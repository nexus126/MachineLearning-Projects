{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvEciMUgDwYR"
      },
      "source": [
        "# Esercitazione su Spacy e Annotazione dei testi basata su NER\n",
        "\n",
        "#### Author\n",
        "Federico Ranadi, May 2023.  \n",
        "federico.ranaldi99@gmail.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-PGA6wM0L10"
      },
      "source": [
        "# Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lj-suJTxzvqp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L6CzI8QcDwYZ"
      },
      "outputs": [],
      "source": [
        "# option to print all the value of cells in DataFrames\n",
        "pd.set_option(\"max_colwidth\", None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwtiTgOgDwYa"
      },
      "source": [
        "### Install spacy and download the english pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USIwN350DwYa",
        "outputId": "7b07c320-ce2c-4d1f-e7e3-717bc4da40d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.2)\n",
            "2023-05-22 16:16:53.501569: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-22 16:16:54.458726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-05-22 16:16:55.679165: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-22 16:16:55.679636: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-05-22 16:16:55.679815: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "# install the spacy module\n",
        "!pip install spacy\n",
        "\n",
        "# download the english pipeline here\n",
        "# 'it_core_news_sm' for italian texts\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "B7SpV2heDwYb"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR2_VToMDwYc"
      },
      "source": [
        "# Annotation example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BEbW8FVPDwYc"
      },
      "outputs": [],
      "source": [
        "input_string = \"In 1982, Mark drove his car from Los Angeles to Las Vegas until 5 of july\"\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nlp(\"ciao bello\"))\n",
        "print(type(nlp(\"ciao bello\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVmzXshQFLRr",
        "outputId": "7417f84d-ac0d-41bd-9330-fcc42cd458f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ciao bello\n",
            "<class 'spacy.tokens.doc.Doc'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "B0zgtke8DwYd"
      },
      "outputs": [],
      "source": [
        "def print_annotation(input_string):\n",
        "    doc = nlp(input_string)\n",
        "    \n",
        "    df = pd.DataFrame({\n",
        "        \"id\": [],\n",
        "        \"word\": [],\n",
        "        \"lemma\": [],\n",
        "        \"tag\": [],\n",
        "        \"entity\": [],\n",
        "        \"dependency\": [],\n",
        "        \"head_id\": []\n",
        "    })\n",
        "\n",
        "    for sent in doc.sents:\n",
        "        for i, word in enumerate(sent):\n",
        "            if word.head is word:\n",
        "                head_idx = 0\n",
        "            else:\n",
        "                head_idx = doc[i].head.i+1\n",
        "            if head_idx == i + 1:\n",
        "                head_idx = 0\n",
        "\n",
        "            entity_tag = word.ent_type_\n",
        "            if len(entity_tag) == 0:\n",
        "                entity_tag = \"O\"\n",
        "            \n",
        "            word_obj = {\"id\": str(i+1), \"word\": str(word), \"lemma\": word.lemma_, \"tag\": word.tag_, \"entity\": entity_tag,\n",
        "                                    \"dependency\": word.dep_, \"head_id\": str(head_idx)}\n",
        "            df = df.append(word_obj, ignore_index=True)\n",
        "    display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m4M3VuDoDwYd",
        "outputId": "b792c391-a030-4ee3-d652-fa634a4b9d5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n",
            "<ipython-input-7-e107430fbb37>:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(word_obj, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    id     word    lemma   tag  entity dependency head_id\n",
              "0    1       In       in    IN       O       prep       5\n",
              "1    2     1982     1982    CD    DATE       pobj       1\n",
              "2    3        ,        ,     ,       O      punct       5\n",
              "3    4     Mark     Mark   NNP  PERSON      nsubj       5\n",
              "4    5    drove    drive   VBD       O       ROOT       0\n",
              "5    6      his      his  PRP$       O       poss       7\n",
              "6    7      car      car    NN       O       dobj       5\n",
              "7    8     from     from    IN       O       prep       5\n",
              "8    9      Los      Los   NNP     GPE   compound      10\n",
              "9   10  Angeles  Angeles   NNP     GPE       pobj       8\n",
              "10  11       to       to    IN       O       prep       5\n",
              "11  12      Las      Las   NNP     GPE   compound      13\n",
              "12  13    Vegas    Vegas   NNP     GPE       pobj      11\n",
              "13  14    until    until    IN       O       prep       5\n",
              "14  15        5        5    CD    DATE       pobj      14\n",
              "15  16       of       of    IN    DATE       prep      15\n",
              "16  17     july     july   NNP    DATE       pobj      16"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9e77175-b36b-4b80-bad5-db994669d92b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>word</th>\n",
              "      <th>lemma</th>\n",
              "      <th>tag</th>\n",
              "      <th>entity</th>\n",
              "      <th>dependency</th>\n",
              "      <th>head_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>In</td>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>prep</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1982</td>\n",
              "      <td>1982</td>\n",
              "      <td>CD</td>\n",
              "      <td>DATE</td>\n",
              "      <td>pobj</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "      <td>punct</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Mark</td>\n",
              "      <td>Mark</td>\n",
              "      <td>NNP</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>nsubj</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>drove</td>\n",
              "      <td>drive</td>\n",
              "      <td>VBD</td>\n",
              "      <td>O</td>\n",
              "      <td>ROOT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>his</td>\n",
              "      <td>his</td>\n",
              "      <td>PRP$</td>\n",
              "      <td>O</td>\n",
              "      <td>poss</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>car</td>\n",
              "      <td>car</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "      <td>dobj</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>from</td>\n",
              "      <td>from</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>prep</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Los</td>\n",
              "      <td>Los</td>\n",
              "      <td>NNP</td>\n",
              "      <td>GPE</td>\n",
              "      <td>compound</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Angeles</td>\n",
              "      <td>Angeles</td>\n",
              "      <td>NNP</td>\n",
              "      <td>GPE</td>\n",
              "      <td>pobj</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>to</td>\n",
              "      <td>to</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>prep</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>Las</td>\n",
              "      <td>Las</td>\n",
              "      <td>NNP</td>\n",
              "      <td>GPE</td>\n",
              "      <td>compound</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>Vegas</td>\n",
              "      <td>Vegas</td>\n",
              "      <td>NNP</td>\n",
              "      <td>GPE</td>\n",
              "      <td>pobj</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>until</td>\n",
              "      <td>until</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>prep</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>CD</td>\n",
              "      <td>DATE</td>\n",
              "      <td>pobj</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>DATE</td>\n",
              "      <td>prep</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>july</td>\n",
              "      <td>july</td>\n",
              "      <td>NNP</td>\n",
              "      <td>DATE</td>\n",
              "      <td>pobj</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9e77175-b36b-4b80-bad5-db994669d92b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9e77175-b36b-4b80-bad5-db994669d92b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9e77175-b36b-4b80-bad5-db994669d92b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print_annotation(input_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDGd2-LgDwYe"
      },
      "outputs": [],
      "source": [
        "def visualize_annotation(input_string, style=\"dep\"):\n",
        "    doc = nlp(input_string)\n",
        "    # style can be either \"dep\" or \"ent\"\n",
        "    displacy.render(doc, style=style, jupyter=True, options={\"distance\": 100}) #distance default 140"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "SdbUGw04DwYe",
        "outputId": "50798fbe-7fde-419d-df85-f9147ef6925d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"a655df04b8dc4762be3f42e5a0b8ca4e-0\" class=\"displacy\" width=\"1650\" height=\"387.0\" direction=\"ltr\" style=\"max-width: none; height: 387.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">In</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">1982,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">Mark</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">drove</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">his</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">car</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">from</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Los</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">Angeles</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1050\">Las</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1050\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">Vegas</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">until</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1350\">5</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1350\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1550\">july</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1550\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-0\" stroke-width=\"2px\" d=\"M70,252.0 C70,152.0 335.0,152.0 335.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,254.0 L62,242.0 78,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-1\" stroke-width=\"2px\" d=\"M70,252.0 C70,202.0 130.0,202.0 130.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M130.0,254.0 L138.0,242.0 122.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-2\" stroke-width=\"2px\" d=\"M270,252.0 C270,202.0 330.0,202.0 330.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M270,254.0 L262,242.0 278,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-3\" stroke-width=\"2px\" d=\"M470,252.0 C470,202.0 530.0,202.0 530.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M470,254.0 L462,242.0 478,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-4\" stroke-width=\"2px\" d=\"M370,252.0 C370,152.0 535.0,152.0 535.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M535.0,254.0 L543.0,242.0 527.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-5\" stroke-width=\"2px\" d=\"M370,252.0 C370,102.0 640.0,102.0 640.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M640.0,254.0 L648.0,242.0 632.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-6\" stroke-width=\"2px\" d=\"M770,252.0 C770,202.0 830.0,202.0 830.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,254.0 L762,242.0 778,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-7\" stroke-width=\"2px\" d=\"M670,252.0 C670,152.0 835.0,152.0 835.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M835.0,254.0 L843.0,242.0 827.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-8\" stroke-width=\"2px\" d=\"M370,252.0 C370,52.0 945.0,52.0 945.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945.0,254.0 L953.0,242.0 937.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-9\" stroke-width=\"2px\" d=\"M1070,252.0 C1070,202.0 1130.0,202.0 1130.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1070,254.0 L1062,242.0 1078,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-10\" stroke-width=\"2px\" d=\"M970,252.0 C970,152.0 1135.0,152.0 1135.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1135.0,254.0 L1143.0,242.0 1127.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-11\" stroke-width=\"2px\" d=\"M370,252.0 C370,2.0 1250.0,2.0 1250.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1250.0,254.0 L1258.0,242.0 1242.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-12\" stroke-width=\"2px\" d=\"M1270,252.0 C1270,202.0 1330.0,202.0 1330.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1330.0,254.0 L1338.0,242.0 1322.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-13\" stroke-width=\"2px\" d=\"M1370,252.0 C1370,202.0 1430.0,202.0 1430.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1430.0,254.0 L1438.0,242.0 1422.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-14\" stroke-width=\"2px\" d=\"M1470,252.0 C1470,202.0 1530.0,202.0 1530.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-a655df04b8dc4762be3f42e5a0b8ca4e-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1530.0,254.0 L1538.0,242.0 1522.0,242.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "visualize_annotation(input_string, style=\"dep\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "RrwLKiWDDwYe",
        "outputId": "9a655aad-a3bc-4b11-9779-dc63d34d0c91"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">In \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1982\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mark\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " drove his car from \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Los Angeles\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " to \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Las Vegas\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " until \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    5 of july\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "visualize_annotation(input_string, style=\"ent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-mT_MATDwYf"
      },
      "source": [
        "\n",
        "# Information extraction\n",
        "\n",
        "Get information about a particular word in a given string."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This function of code computes the annotation for each word: a set of usefull informations extracted by the dependency parsing of the input string...\n",
        "#...Between these informations we have the id,head_id,tag,entity(obtained with NER),...\n",
        "#It returns the annotation of the entire sentence\n",
        "\n",
        "def get_sentence_annotation(input_string):\n",
        "    doc = nlp(input_string)\n",
        "\n",
        "    words = []\n",
        "    for sent in doc.sents:  \n",
        "        for i, word in enumerate(sent): \n",
        "            if word.head is word: \n",
        "                head_idx = 0\n",
        "            else:\n",
        "                head_idx = doc[i].head.i+1  \n",
        "            if head_idx == i + 1:\n",
        "                head_idx = 0\n",
        "\n",
        "            entity_tag = word.ent_type_\n",
        "            if len(entity_tag) == 0:\n",
        "                entity_tag = \"O\"\n",
        "            \n",
        "            word_obj = {\"id\": i+1, \"word\": str(word), \"lemma\": word.lemma_, \"tag\": word.tag_, \"entity\": entity_tag,\n",
        "                                    \"dependency\": word.dep_, \"head_id\": head_idx}\n",
        "            words.append(word_obj)\n",
        "    \n",
        "    return words"
      ],
      "metadata": {
        "id": "uYm1z8J1PqbM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_sentence_annotation(input_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EntYbSOQVFE",
        "outputId": "86a03ddc-8076-4eb7-ec28-8e67f226f7a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 1,\n",
              "  'word': 'In',\n",
              "  'lemma': 'in',\n",
              "  'tag': 'IN',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'prep',\n",
              "  'head_id': 5},\n",
              " {'id': 2,\n",
              "  'word': '1982',\n",
              "  'lemma': '1982',\n",
              "  'tag': 'CD',\n",
              "  'entity': 'DATE',\n",
              "  'dependency': 'pobj',\n",
              "  'head_id': 1},\n",
              " {'id': 3,\n",
              "  'word': ',',\n",
              "  'lemma': ',',\n",
              "  'tag': ',',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'punct',\n",
              "  'head_id': 5},\n",
              " {'id': 4,\n",
              "  'word': 'Mark',\n",
              "  'lemma': 'Mark',\n",
              "  'tag': 'NNP',\n",
              "  'entity': 'PERSON',\n",
              "  'dependency': 'nsubj',\n",
              "  'head_id': 5},\n",
              " {'id': 5,\n",
              "  'word': 'drove',\n",
              "  'lemma': 'drive',\n",
              "  'tag': 'VBD',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'ROOT',\n",
              "  'head_id': 0},\n",
              " {'id': 6,\n",
              "  'word': 'his',\n",
              "  'lemma': 'his',\n",
              "  'tag': 'PRP$',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'poss',\n",
              "  'head_id': 7},\n",
              " {'id': 7,\n",
              "  'word': 'car',\n",
              "  'lemma': 'car',\n",
              "  'tag': 'NN',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'dobj',\n",
              "  'head_id': 5},\n",
              " {'id': 8,\n",
              "  'word': 'from',\n",
              "  'lemma': 'from',\n",
              "  'tag': 'IN',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'prep',\n",
              "  'head_id': 5},\n",
              " {'id': 9,\n",
              "  'word': 'Los',\n",
              "  'lemma': 'Los',\n",
              "  'tag': 'NNP',\n",
              "  'entity': 'GPE',\n",
              "  'dependency': 'compound',\n",
              "  'head_id': 10},\n",
              " {'id': 10,\n",
              "  'word': 'Angeles',\n",
              "  'lemma': 'Angeles',\n",
              "  'tag': 'NNP',\n",
              "  'entity': 'GPE',\n",
              "  'dependency': 'pobj',\n",
              "  'head_id': 8},\n",
              " {'id': 11,\n",
              "  'word': 'to',\n",
              "  'lemma': 'to',\n",
              "  'tag': 'IN',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'prep',\n",
              "  'head_id': 5},\n",
              " {'id': 12,\n",
              "  'word': 'Las',\n",
              "  'lemma': 'Las',\n",
              "  'tag': 'NNP',\n",
              "  'entity': 'GPE',\n",
              "  'dependency': 'compound',\n",
              "  'head_id': 13},\n",
              " {'id': 13,\n",
              "  'word': 'Vegas',\n",
              "  'lemma': 'Vegas',\n",
              "  'tag': 'NNP',\n",
              "  'entity': 'GPE',\n",
              "  'dependency': 'pobj',\n",
              "  'head_id': 11},\n",
              " {'id': 14,\n",
              "  'word': 'until',\n",
              "  'lemma': 'until',\n",
              "  'tag': 'IN',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'prep',\n",
              "  'head_id': 5},\n",
              " {'id': 15,\n",
              "  'word': '5',\n",
              "  'lemma': '5',\n",
              "  'tag': 'CD',\n",
              "  'entity': 'DATE',\n",
              "  'dependency': 'pobj',\n",
              "  'head_id': 14},\n",
              " {'id': 16,\n",
              "  'word': 'of',\n",
              "  'lemma': 'of',\n",
              "  'tag': 'IN',\n",
              "  'entity': 'DATE',\n",
              "  'dependency': 'prep',\n",
              "  'head_id': 15},\n",
              " {'id': 17,\n",
              "  'word': 'july',\n",
              "  'lemma': 'july',\n",
              "  'tag': 'NNP',\n",
              "  'entity': 'DATE',\n",
              "  'dependency': 'pobj',\n",
              "  'head_id': 16}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LRnaJnYEDwYf"
      },
      "outputs": [],
      "source": [
        "#This function takes in input a sentence and a specyfic word\n",
        "#It returns the annotation of that word\n",
        "\n",
        "def get_word_annotation(input_string, word_string):\n",
        "    \n",
        "    words=get_sentence_annotation(input_string)\n",
        "    \n",
        "    for word in words:\n",
        "        if word[\"word\"] == word_string:\n",
        "            return word\n",
        "  \n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZaosnArDwYg",
        "outputId": "b075b340-4a79-4855-b343-7c78617097c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 4, 'word': 'Mark', 'lemma': 'Mark', 'tag': 'NNP', 'entity': 'PERSON', 'dependency': 'nsubj', 'head_id': 5}\n"
          ]
        }
      ],
      "source": [
        "print(get_word_annotation(input_string, \"Mark\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This function takes in input a string and a dependency_type(such as \"nsubj\",\"prep\"...) \n",
        "#It returns the head_id and the tail_id of all the couples of words involved in that dependency-type\n",
        "\n",
        "def search_relation(input_string, relation_string):\n",
        "  \n",
        "    words = get_sentence_annotation(input_string)\n",
        "    \n",
        "    #each word annotation is a dictionary\n",
        "    #words is the list of the word-annotations\n",
        "\n",
        "    relations_head_tail = [] ##these are respectively the ids of the heads and the tails of each the relations \n",
        "    \n",
        "    for word in words:\n",
        "        if(word[\"dependency\"]==relation_string):\n",
        "          relations_head_tail.append([word[\"head_id\"],word[\"id\"]])\n",
        "\n",
        "    return relations_head_tail"
      ],
      "metadata": {
        "id": "fG1bVZ1sLsvR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_relation(input_string, \"prep\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqVfh3V5Ncb9",
        "outputId": "7fc8c5b6-30cb-4365-edf6-9c5b4009790c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[5, 1], [5, 8], [5, 11], [5, 14], [15, 16]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This function takes in input a string and a dependency_type(such as \"nsubj\",\"prep\"...) \n",
        "#It returns a triple containing the lemmas of the head_word and tail_word in the dependency respectively and the dependency-type\n",
        "\n",
        "def get_triple_relation(input_string, relation_string):\n",
        "  \n",
        "  triples_relation=[]\n",
        "\n",
        "  relations_head_tail = search_relation(input_string, relation_string)\n",
        "  \n",
        "  words = get_sentence_annotation(input_string)\n",
        "\n",
        "  for ids in relations_head_tail:\n",
        "    for word in words:\n",
        "      if (word[\"id\"] == ids[0]): \n",
        "        lemma_head = word[\"lemma\"]\n",
        "      if (word[\"id\"] == ids[1]):\n",
        "        lemma_tail = word[\"lemma\"]\n",
        "    triples_relation.append([lemma_head,relation_string,lemma_tail])\n",
        "\n",
        "  return triples_relation"
      ],
      "metadata": {
        "id": "P1zvtdk8Ou5d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_triple_relation(input_string, \"prep\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmWMM8AYVF4r",
        "outputId": "4ecf5494-7cee-443c-c6bc-dba25200777d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['drive', 'prep', 'in'], ['drive', 'prep', 'from'], ['drive', 'prep', 'to'], ['drive', 'prep', 'until'], ['5', 'prep', 'of']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prpaCbFeDwYg"
      },
      "source": [
        "### Exercise 2: Search for entities\n",
        "\n",
        "Define a method that takes in input a sentence (`input_string`) and the name of an entity type (`entity_type_string`), parses with spacy the input and returns the words (the `objects`! not the strings) described by that entity. If the entity type is not present, return an empty array.\n",
        "\n",
        "```\n",
        "def search_entity(input_string, entity_type_string):\n",
        "    return word_obj_list\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This function takes in input a sentence and a entity-type\n",
        "#I returns the id of each word associated to that entity-type\n",
        "\n",
        "def search_entity(input_string, entity_type_string):\n",
        "    ids = []\n",
        "    \n",
        "    words = get_sentence_annotation(input_string)\n",
        "    \n",
        "    for word in words:\n",
        "      if(word[\"entity\"] == entity_type_string):\n",
        "        ids.append(word[\"id\"])\n",
        "    return ids"
      ],
      "metadata": {
        "id": "SQaMwI_HvE1O"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_entity(input_string,\"DATE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQeDgHaPwX4m",
        "outputId": "a5c45aa3-0789-496a-ce9c-fa39f7abde92"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 15, 16, 17]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This function takes as input a sentence and a entity-type\n",
        "#It returns couples(lemma,entity_type) of all words associated to that entity-type\n",
        "\n",
        "def get_couple_entity(input_string, entity_type_string):\n",
        "  \n",
        "  couples= []  \n",
        "\n",
        "  ids=search_entity(input_string,entity_type_string)\n",
        "\n",
        "  words = get_sentence_annotation(input_string)\n",
        "\n",
        "  for id in ids:\n",
        "    for word in words:\n",
        "      if(word[\"id\"] == id):\n",
        "        lemma = word[\"lemma\"]\n",
        "    couples.append([lemma,entity_type_string])\n",
        "  \n",
        "  return couples"
      ],
      "metadata": {
        "id": "4IHlbnIcwl0_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_couple_entity(input_string,\"DATE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FBhGpZtwlyO",
        "outputId": "3a1ba804-bfab-4531-c612-fda02c2eb384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['1982', 'DATE'], ['5', 'DATE'], ['of', 'DATE'], ['july', 'DATE']]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuwJeABoDwYh"
      },
      "source": [
        "### Exercise 3: Enriching the sentences\n",
        "\n",
        "For every sentence in the QuestionClassification dataset, extract the `subject-verb` relation and the `verb-object` relation. Add these couples to the original input, divided by the `#`:\n",
        "\n",
        "- Sentence: '*What is the full form of .com?*' \n",
        "- `subject-verb`: *What is*  \n",
        "- `verb-object`: *is the full form* \n",
        "- Enriched sentence: '*What is the full form of .com? # What is # is the full form*'  \n",
        "\n",
        "Store the enriched sentences in a new dataframe and train a classifier (SVM, NB, Rocchio..) and evaluate it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "z7ZksCt-yoHi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# option to print all the value of cells in DataFrames\n",
        "pd.set_option(\"max_colwidth\", None)"
      ],
      "metadata": {
        "id": "NCexKUuqzmGv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = pd.read_csv(\"./train.csv\")\n",
        "testing_data = pd.read_csv(\"./test.csv\")\n",
        "\n",
        "classes = list(np.unique(testing_data['classes']))\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c7tUxMjzp1s",
        "outputId": "dd6a2e70-8510-4045-dd6e-2abc9952650b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ABBR', 'DESC', 'ENTY', 'HUM', 'LOC', 'NUM']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_questions=list(training_data[\"questions\"])\n",
        "test_questions=list(testing_data[\"questions\"])"
      ],
      "metadata": {
        "id": "dMHW75lIzpy3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list of spacy dependencies\n",
        "\n",
        "for label in nlp.get_pipe(\"parser\").labels:\n",
        "    print(label, \" -- \", spacy.explain(label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDggJeac0QCW",
        "outputId": "57f860b6-c4e7-45de-a026-67bf385d9f0a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROOT  --  root\n",
            "acl  --  clausal modifier of noun (adjectival clause)\n",
            "acomp  --  adjectival complement\n",
            "advcl  --  adverbial clause modifier\n",
            "advmod  --  adverbial modifier\n",
            "agent  --  agent\n",
            "amod  --  adjectival modifier\n",
            "appos  --  appositional modifier\n",
            "attr  --  attribute\n",
            "aux  --  auxiliary\n",
            "auxpass  --  auxiliary (passive)\n",
            "case  --  case marking\n",
            "cc  --  coordinating conjunction\n",
            "ccomp  --  clausal complement\n",
            "compound  --  compound\n",
            "conj  --  conjunct\n",
            "csubj  --  clausal subject\n",
            "csubjpass  --  clausal subject (passive)\n",
            "dative  --  dative\n",
            "dep  --  unclassified dependent\n",
            "det  --  determiner\n",
            "dobj  --  direct object\n",
            "expl  --  expletive\n",
            "intj  --  interjection\n",
            "mark  --  marker\n",
            "meta  --  meta modifier\n",
            "neg  --  negation modifier\n",
            "nmod  --  modifier of nominal\n",
            "npadvmod  --  noun phrase as adverbial modifier\n",
            "nsubj  --  nominal subject\n",
            "nsubjpass  --  nominal subject (passive)\n",
            "nummod  --  numeric modifier\n",
            "oprd  --  object predicate\n",
            "parataxis  --  parataxis\n",
            "pcomp  --  complement of preposition\n",
            "pobj  --  object of preposition\n",
            "poss  --  possession modifier\n",
            "preconj  --  pre-correlative conjunction\n",
            "predet  --  None\n",
            "prep  --  prepositional modifier\n",
            "prt  --  particle\n",
            "punct  --  punctuation\n",
            "quantmod  --  modifier of quantifier\n",
            "relcl  --  relative clause modifier\n",
            "xcomp  --  open clausal complement\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/glossary.py:19: UserWarning: [W118] Term 'predet' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
            "  warnings.warn(Warnings.W118.format(term=term))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " We are now considering only those dependecies whose role is of connecting subject-verb and verb-object.\n",
        "\n",
        " These dependecies are : nsubj, dobj, csubj, csubjpass, pobj.\n",
        "\n",
        " We will consider only nsubj and dobj (for simplicity and for avoiding dependencies overlapping).\n",
        "\n",
        " Givene a text, we are going to annotate these kinds of dependencies in this way:\n",
        "\n",
        " Example\n",
        " \n",
        " INPUT: \"How did serfdom develop in and then leave Russia ?\"\n",
        "\n",
        "Text Annotation :\n",
        "\n",
        "    ID   WORD      DEPENDENCY    HEAD_ID\n",
        "\n",
        "    1    How       advmod         4\n",
        "    2    did       aux            4\n",
        "    3    serfdom   nsubj          4\n",
        "    4    develop   ROOT           0\n",
        "    5    in        prep           4\n",
        "    6    and       cc             4\n",
        "    7    then      advmod         8\n",
        "    8    leave     conj           4\n",
        "    9    Russia    dobj           8\n",
        "    10   ?         punct          4\n",
        "\n",
        "  OUTPUT: \"How did # serfdom develop # in and then # leave Russia # ?\""
      ],
      "metadata": {
        "id": "C8DeSgfIhjin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words_list(annotated_sentence): #return the list of words annotated (it receives as input the sentence annotation)\n",
        "  l=[]\n",
        "  for word in annotated_sentence :\n",
        "    l.append(word['word'])\n",
        "  return l"
      ],
      "metadata": {
        "id": "hx-dOFqHkefI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_enriched_sentence(sentence):\n",
        "    deps = [\"nsubj\",\"dobj\"]\n",
        "    annotated_sentence = get_sentence_annotation(sentence)\n",
        "\n",
        "    #find the ids of the words involved in the dependency\n",
        "    for dep in deps:\n",
        "        dep_head_tail = []\n",
        "        for word in annotated_sentence:\n",
        "            if(word[\"dependency\"]==dep):\n",
        "              dep_head_tail.append(word[\"head_id\"])\n",
        "              dep_head_tail.append(word[\"id\"])\n",
        "        dep_head_tail.sort()\n",
        "        \n",
        "          #modify words with \"#\"...\n",
        "        if(len(dep_head_tail) > 1):\n",
        "          for word in annotated_sentence:\n",
        "            if(word['id'] == dep_head_tail[0]):\n",
        "              word['word'] = \"#\" + word['word']\n",
        "            if(word['id'] == dep_head_tail[1]):\n",
        "              word['word'] = word['word'] + \"#\"\n",
        "    \n",
        "    l = get_words_list(annotated_sentence)\n",
        "\n",
        "    #now get the enriched text (NOTE: we want to tokenize togethere head and tail of the relation)!\n",
        "    enriched_sentence=''\n",
        "\n",
        "    enriched_sentence= \" \".join(l)\n",
        "\n",
        "    return enriched_sentence"
      ],
      "metadata": {
        "id": "UJL_f8_SjsJX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's enrich all the dataset\n",
        "\n",
        "train_enriched_questions=[]\n",
        "test_enriched_questions=[]\n",
        "\n",
        "for question in train_questions:\n",
        "  train_enriched_questions.append(get_enriched_sentence(question))\n",
        "\n",
        "for question in test_questions:\n",
        "  test_enriched_questions.append(get_enriched_sentence(question))\n"
      ],
      "metadata": {
        "id": "cinwBXFFjJhk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "X3b_lnDXE7l_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize the dataset and store it inside the dataframe\n",
        "#NOTE: do note remove stopwords like \"?\" ,\"!\",\":\" \n",
        "#In particulare words surrounded by \"#\" witness a dependency relation inside the sentence which can be usefull for our task\n",
        "nltk.download('punkt')\n",
        "\n",
        "training_data['enriched_questions'] = list(map(lambda sent: nltk.word_tokenize(sent), train_enriched_questions))\n",
        "testing_data['enriched_questions'] = list(map(lambda sent: nltk.word_tokenize(sent), test_enriched_questions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp995xU8Bsl8",
        "outputId": "e1933959-dd75-43b6-9968-a3356fbeb021"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#transforming list of token into a string...\n",
        "#\" \".join(str(x) for x in xs)\n",
        "training_data[\"enriched_questions\"] = training_data[\"enriched_questions\"].apply(lambda l: ' '.join(str(t) for t in l))\n",
        "testing_data[\"enriched_questions\"] = testing_data[\"enriched_questions\"].apply(lambda l: ' '.join(str(t) for t in l))"
      ],
      "metadata": {
        "id": "OMACbfkRH1Mw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Hbed4DLtJQR7",
        "outputId": "e0453d10-8b5a-4f2d-df9f-3c8c2d452d58"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                              questions  \\\n",
              "0                    How did serfdom develop in and then leave Russia ?   \n",
              "1                      What films featured the character Popeye Doyle ?   \n",
              "2                   How can I find a list of celebrities ' real names ?   \n",
              "3  What fowl grabs the spotlight after the Chinese Year of the Monkey ?   \n",
              "4                                       What is the full form of .com ?   \n",
              "\n",
              "  classes  \\\n",
              "0    DESC   \n",
              "1    ENTY   \n",
              "2    DESC   \n",
              "3    ENTY   \n",
              "4    ABBR   \n",
              "\n",
              "                                                             enriched_questions  \n",
              "0                    How did # serfdom develop # in and then # leave Russia # ?  \n",
              "1                      What # films # featured # the character # Popeye Doyle ?  \n",
              "2                   How can # I # find # a list # of celebrities ' real names ?  \n",
              "3  What # fowl # grabs # the spotlight # after the Chinese Year of the Monkey ?  \n",
              "4                                           What # is the full form # of .com ?  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7c3482e-e00c-4990-86a6-b3ea53bbb9d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>questions</th>\n",
              "      <th>classes</th>\n",
              "      <th>enriched_questions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How did serfdom develop in and then leave Russia ?</td>\n",
              "      <td>DESC</td>\n",
              "      <td>How did # serfdom develop # in and then # leave Russia # ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What films featured the character Popeye Doyle ?</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>What # films # featured # the character # Popeye Doyle ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I find a list of celebrities ' real names ?</td>\n",
              "      <td>DESC</td>\n",
              "      <td>How can # I # find # a list # of celebrities ' real names ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What fowl grabs the spotlight after the Chinese Year of the Monkey ?</td>\n",
              "      <td>ENTY</td>\n",
              "      <td>What # fowl # grabs # the spotlight # after the Chinese Year of the Monkey ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the full form of .com ?</td>\n",
              "      <td>ABBR</td>\n",
              "      <td>What # is the full form # of .com ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7c3482e-e00c-4990-86a6-b3ea53bbb9d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7c3482e-e00c-4990-86a6-b3ea53bbb9d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7c3482e-e00c-4990-86a6-b3ea53bbb9d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: using BOW-vectorizer we are losing informations about the position of a word inside the sentence\n",
        "# hence we are partially losing the informations we have encoded before (like the head and tail of a dependecy relation)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(training_data['enriched_questions'].tolist())\n",
        "X_test = vectorizer.transform(testing_data['enriched_questions'].tolist())\n",
        "y_train = training_data['classes'].tolist()\n",
        "y_test = testing_data['classes'].tolist()"
      ],
      "metadata": {
        "id": "vGkaaXEXHIL8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iHvn8ytHH_q",
        "outputId": "9d9a3b2b-327b-44f9-a590-b88709f33617"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'how': 3786,\n",
              " 'did': 2306,\n",
              " 'serfdom': 6748,\n",
              " 'develop': 2273,\n",
              " 'in': 3888,\n",
              " 'and': 509,\n",
              " 'then': 7587,\n",
              " 'leave': 4390,\n",
              " 'russia': 6553,\n",
              " 'what': 8182,\n",
              " 'films': 3009,\n",
              " 'featured': 2953,\n",
              " 'the': 7576,\n",
              " 'character': 1523,\n",
              " 'popeye': 5873,\n",
              " 'doyle': 2461,\n",
              " 'can': 1350,\n",
              " 'find': 3015,\n",
              " 'list': 4496,\n",
              " 'of': 5370,\n",
              " 'celebrities': 1473,\n",
              " 'real': 6229,\n",
              " 'names': 5144,\n",
              " 'fowl': 3163,\n",
              " 'grabs': 3424,\n",
              " 'spotlight': 7133,\n",
              " 'after': 383,\n",
              " 'chinese': 1578,\n",
              " 'year': 8351,\n",
              " 'monkey': 5013,\n",
              " 'is': 4032,\n",
              " 'full': 3225,\n",
              " 'form': 3134,\n",
              " 'com': 1748,\n",
              " 'contemptible': 1885,\n",
              " 'scoundrel': 6668,\n",
              " 'stole': 7246,\n",
              " 'cork': 1933,\n",
              " 'from': 3213,\n",
              " 'my': 5122,\n",
              " 'lunch': 4590,\n",
              " 'team': 7494,\n",
              " 'baseball': 832,\n",
              " 'st': 7156,\n",
              " 'louis': 4563,\n",
              " 'browns': 1208,\n",
              " 'become': 887,\n",
              " 'oldest': 5392,\n",
              " 'profession': 6015,\n",
              " 'are': 622,\n",
              " 'liver': 4511,\n",
              " 'enzymes': 2727,\n",
              " 'name': 5142,\n",
              " 'scar': 6637,\n",
              " 'faced': 2874,\n",
              " 'bounty': 1124,\n",
              " 'hunter': 3812,\n",
              " 'old': 5390,\n",
              " 'west': 8174,\n",
              " 'when': 8188,\n",
              " 'was': 8113,\n",
              " 'ozzy': 5515,\n",
              " 'osbourne': 5459,\n",
              " 'born': 1108,\n",
              " 'why': 8206,\n",
              " 'do': 2395,\n",
              " 'heavier': 3624,\n",
              " 'objects': 5344,\n",
              " 'travel': 7763,\n",
              " 'downhill': 2457,\n",
              " 'faster': 2927,\n",
              " 'who': 8199,\n",
              " 'pride': 5972,\n",
              " 'yankees': 8346,\n",
              " 'killed': 4243,\n",
              " 'gandhi': 3266,\n",
              " 'considered': 1864,\n",
              " 'costliest': 1956,\n",
              " 'disaster': 2351,\n",
              " 'insurance': 3977,\n",
              " 'industry': 3927,\n",
              " 'has': 3575,\n",
              " 'ever': 2794,\n",
              " 'sprawling': 7136,\n",
              " 'state': 7194,\n",
              " 'boasts': 1062,\n",
              " 'most': 5052,\n",
              " 'airports': 417,\n",
              " 'only': 5411,\n",
              " 'repealed': 6330,\n",
              " 'amendment': 489,\n",
              " 'to': 7664,\n",
              " 'constitution': 1874,\n",
              " 'deal': 2168,\n",
              " 'with': 8264,\n",
              " 'many': 4713,\n",
              " 'jews': 4117,\n",
              " 'were': 8172,\n",
              " 'executed': 2818,\n",
              " 'concentration': 1818,\n",
              " 'camps': 1348,\n",
              " 'during': 2530,\n",
              " 'wwii': 8332,\n",
              " 'nine': 5261,\n",
              " 'inch': 3893,\n",
              " 'nails': 5139,\n",
              " 'an': 503,\n",
              " 'annotated': 539,\n",
              " 'bibliography': 975,\n",
              " 'date': 2144,\n",
              " 'boxing': 1139,\n",
              " 'day': 2155,\n",
              " 'articles': 652,\n",
              " 'clothing': 1678,\n",
              " 'tokens': 7670,\n",
              " 'monopoly': 5015,\n",
              " '11': 6,\n",
              " 'famous': 2903,\n",
              " 'martyrs': 4761,\n",
              " 'olympic': 5400,\n",
              " 'motto': 5062,\n",
              " 'origin': 5447,\n",
              " 'scarlett': 6640,\n",
              " 'second': 6704,\n",
              " 'used': 7927,\n",
              " 'vowel': 8072,\n",
              " 'english': 2700,\n",
              " 'inventor': 4008,\n",
              " 'silly': 6890,\n",
              " 'putty': 6113,\n",
              " 'highest': 3679,\n",
              " 'waterfall': 8126,\n",
              " 'united': 7892,\n",
              " 'states': 7197,\n",
              " 'golf': 3395,\n",
              " 'course': 1981,\n",
              " 'myrtle': 5124,\n",
              " 'beach': 862,\n",
              " 'which': 8190,\n",
              " 'two': 7849,\n",
              " 'enclose': 2682,\n",
              " 'chesapeake': 1550,\n",
              " 'bay': 859,\n",
              " 'does': 2402,\n",
              " 'abbreviation': 268,\n",
              " 'aids': 403,\n",
              " 'stand': 7174,\n",
              " 'for': 3115,\n",
              " 'spermologer': 7108,\n",
              " 'collect': 1723,\n",
              " 'points': 5833,\n",
              " 'make': 4665,\n",
              " 'up': 7906,\n",
              " 'perfect': 5664,\n",
              " 'fivepin': 3045,\n",
              " 'bowling': 1133,\n",
              " 'score': 6660,\n",
              " 'company': 1791,\n",
              " 'that': 7574,\n",
              " 'manufactures': 4711,\n",
              " 'video': 8015,\n",
              " 'game': 3262,\n",
              " 'hardware': 3564,\n",
              " 'sells': 6731,\n",
              " 'super': 7355,\n",
              " 'system': 7436,\n",
              " 'community': 1788,\n",
              " 'chest': 1553,\n",
              " 'cards': 1392,\n",
              " 'there': 7595,\n",
              " 'mormons': 5041,\n",
              " 'believe': 913,\n",
              " 'neanderthal': 5183,\n",
              " 'man': 4685,\n",
              " 'live': 4509,\n",
              " 'religion': 6315,\n",
              " 'isis': 4035,\n",
              " 'nature': 5173,\n",
              " 'goddess': 3379,\n",
              " 'where': 8189,\n",
              " 'adventures': 357,\n",
              " 'swiss': 7416,\n",
              " 'family': 2901,\n",
              " 'robinson': 6459,\n",
              " 'take': 7456,\n",
              " 'place': 5781,\n",
              " 'relative': 6306,\n",
              " 'racoon': 6164,\n",
              " 'sometimes': 7039,\n",
              " 'known': 4277,\n",
              " 'as': 657,\n",
              " 'cat': 1440,\n",
              " 'bear': 868,\n",
              " 'register': 6292,\n",
              " 'website': 8153,\n",
              " 'yahoo': 8340,\n",
              " 'free': 3185,\n",
              " 'cash': 1430,\n",
              " 'conscious': 1856,\n",
              " 'colonel': 1735,\n",
              " 'edwin': 2600,\n",
              " 'drake': 2471,\n",
              " 'first': 3037,\n",
              " 'drill': 2481,\n",
              " 'people': 5656,\n",
              " 'world': 8304,\n",
              " 'speak': 7087,\n",
              " 'french': 3193,\n",
              " 'inches': 3894,\n",
              " 'over': 5489,\n",
              " 'six': 6930,\n",
              " 'feet': 2961,\n",
              " 'venus': 7981,\n",
              " 'de': 2161,\n",
              " 'milo': 4954,\n",
              " 'they': 7601,\n",
              " 'or': 5431,\n",
              " 'choose': 1591,\n",
              " 'witnesses': 8268,\n",
              " 'execution': 2819,\n",
              " '1920s': 89,\n",
              " 'cowboy': 1992,\n",
              " 'star': 7180,\n",
              " 'rode': 6471,\n",
              " 'tony': 7684,\n",
              " 'wonder': 8282,\n",
              " 'horse': 3760,\n",
              " 'cocktail': 1703,\n",
              " 'inspired': 3970,\n",
              " 'john': 4135,\n",
              " 'doxat': 2460,\n",
              " 'write': 8323,\n",
              " 'book': 1093,\n",
              " 'stirred': 7239,\n",
              " 'not': 5310,\n",
              " 'shaken': 6784,\n",
              " 'isps': 4045,\n",
              " 'exist': 2827,\n",
              " 'caribbean': 1397,\n",
              " 'you': 8373,\n",
              " 'ask': 663,\n",
              " 'total': 7703,\n",
              " 'stranger': 7269,\n",
              " 'out': 5478,\n",
              " 'on': 5403,\n",
              " 'weapon': 8144,\n",
              " 'mythological': 5131,\n",
              " 'apollo': 575,\n",
              " 'proficient': 6018,\n",
              " 'country': 1974,\n",
              " 'galapagos': 3251,\n",
              " 'islands': 4039,\n",
              " 'belong': 923,\n",
              " 'ethology': 2781,\n",
              " 'prophet': 6043,\n",
              " 'muslim': 5114,\n",
              " 'term': 7541,\n",
              " '86ed': 248,\n",
              " 'come': 1755,\n",
              " 'snoopy': 6999,\n",
              " 'arch': 611,\n",
              " 'enemy': 2692,\n",
              " 'learning': 4388,\n",
              " 'color': 1740,\n",
              " 'johnny': 4137,\n",
              " 'wears': 8148,\n",
              " 'stage': 7159,\n",
              " 'young': 8375,\n",
              " 'fox': 3164,\n",
              " 'lived': 4510,\n",
              " 'under': 7879,\n",
              " 'flags': 3050,\n",
              " 'kashmir': 4205,\n",
              " 'issue': 4048,\n",
              " 'loop': 4550,\n",
              " 'extended': 2854,\n",
              " 'definition': 2204,\n",
              " 'mean': 4828,\n",
              " 'would': 8311,\n",
              " 'one': 5406,\n",
              " 'paper': 5563,\n",
              " 'it': 4051,\n",
              " 'capital': 1375,\n",
              " 'tirana': 7654,\n",
              " 'titanium': 7658,\n",
              " 'herb': 3656,\n",
              " 'tootsie': 7692,\n",
              " 'next': 5235,\n",
              " 'door': 2439,\n",
              " 'city': 1631,\n",
              " 'relationship': 6305,\n",
              " 'sister': 6923,\n",
              " 'los': 4553,\n",
              " 'angeles': 522,\n",
              " 'caldera': 1320,\n",
              " 'get': 3328,\n",
              " 'calluses': 1332,\n",
              " 'tourist': 7713,\n",
              " 'attractions': 716,\n",
              " 'reims': 6299,\n",
              " 'cushman': 2094,\n",
              " 'wakefield': 8082,\n",
              " 'body': 1070,\n",
              " 'water': 8125,\n",
              " 'danube': 2128,\n",
              " 'river': 6447,\n",
              " 'flow': 3081,\n",
              " 'into': 3994,\n",
              " 'founder': 3156,\n",
              " 'scientology': 6657,\n",
              " 'footed': 3113,\n",
              " 'musca': 5105,\n",
              " 'domestica': 2417,\n",
              " 'enters': 2718,\n",
              " 'house': 3779,\n",
              " 'history': 3704,\n",
              " 'skateboarding': 6934,\n",
              " 'starred': 7183,\n",
              " 'singing': 6908,\n",
              " 'rain': 6179,\n",
              " 'nun': 5329,\n",
              " 'fuel': 3224,\n",
              " 'bricks': 1178,\n",
              " 'recycled': 6266,\n",
              " 'newspaper': 5231,\n",
              " '19th': 170,\n",
              " 'century': 1489,\n",
              " 'painter': 5536,\n",
              " 'died': 2309,\n",
              " 'marquesas': 4746,\n",
              " 'corpus': 1943,\n",
              " 'callosum': 1330,\n",
              " 'part': 5580,\n",
              " 'log': 4533,\n",
              " 'home': 3731,\n",
              " 'page': 5525,\n",
              " 'at': 690,\n",
              " 'headquarters': 3610,\n",
              " 'european': 2787,\n",
              " 'command': 1765,\n",
              " 'nazis': 5179,\n",
              " 'occupy': 5353,\n",
              " 'cd': 1466,\n",
              " 'nns': 5274,\n",
              " 'nnp': 5273,\n",
              " 'nebraska': 5188,\n",
              " 'valuable': 7948,\n",
              " 'resource': 6363,\n",
              " 'species': 7094,\n",
              " 'great': 3453,\n",
              " 'white': 8197,\n",
              " 'shark': 6795,\n",
              " 'head': 3606,\n",
              " 'lice': 4450,\n",
              " 'nickname': 5244,\n",
              " 'mississippi': 4981,\n",
              " 'domesticated': 2418,\n",
              " 'bird': 1003,\n",
              " 'villi': 8026,\n",
              " 'found': 3153,\n",
              " 'small': 6975,\n",
              " 'intestine': 3992,\n",
              " 'king': 4256,\n",
              " 'wenceslas': 8169,\n",
              " 'rule': 6538,\n",
              " 'fear': 2947,\n",
              " 'shadows': 6780,\n",
              " 'five': 3044,\n",
              " 'marx': 4765,\n",
              " 'brothers': 1205,\n",
              " 'new': 5226,\n",
              " 'zealand': 8390,\n",
              " 'excluded': 2814,\n",
              " 'anzus': 566,\n",
              " 'alliance': 451,\n",
              " 'cnn': 1686,\n",
              " 'begin': 903,\n",
              " 'broadcasting': 1193,\n",
              " 'causes': 1457,\n",
              " 'shiver': 6834,\n",
              " 'cold': 1717,\n",
              " 'temperatures': 7525,\n",
              " 'bull': 1243,\n",
              " 'markets': 4740,\n",
              " 'tolkien': 7673,\n",
              " 'features': 2954,\n",
              " 'bilbo': 985,\n",
              " 'baggins': 779,\n",
              " 'central': 1486,\n",
              " 'dew': 2285,\n",
              " 'point': 5831,\n",
              " 'meaning': 4830,\n",
              " 'jesus': 4112,\n",
              " 'logo': 4537,\n",
              " 'circle': 1619,\n",
              " 'cascade': 1426,\n",
              " 'rococo': 6469,\n",
              " 'painting': 5538,\n",
              " 'architecture': 619,\n",
              " 'flourish': 3080,\n",
              " 'national': 5166,\n",
              " 'passenger': 5596,\n",
              " 'rail': 6175,\n",
              " 'called': 1328,\n",
              " 'via': 8003,\n",
              " 'invented': 4005,\n",
              " 'word': 8297,\n",
              " 'attic': 710,\n",
              " 'delilah': 2216,\n",
              " 'samson': 6594,\n",
              " 'hair': 3520,\n",
              " 'kind': 4252,\n",
              " 'animals': 530,\n",
              " 'paleozoic': 5544,\n",
              " 'era': 2741,\n",
              " 'following': 3102,\n",
              " 'rhodes': 6405,\n",
              " 'scholar': 6646,\n",
              " 'comprised': 1812,\n",
              " 'now': 5321,\n",
              " 'defunct': 2206,\n",
              " 'comic': 1762,\n",
              " 'champions': 1507,\n",
              " 'paintball': 5534,\n",
              " 'fort': 3142,\n",
              " 'knox': 4280,\n",
              " 'female': 2968,\n",
              " 'rabbit': 6154,\n",
              " 'japan': 4081,\n",
              " 'chihuahuas': 1568,\n",
              " 'barney': 819,\n",
              " 'rubble': 6527,\n",
              " 'go': 3372,\n",
              " 'work': 8300,\n",
              " 'he': 3605,\n",
              " 'drops': 2496,\n",
              " 'fred': 3181,\n",
              " 'off': 5371,\n",
              " 'flintstones': 3068,\n",
              " 'cartoon': 1421,\n",
              " 'series': 6751,\n",
              " 'four': 3160,\n",
              " 'oceans': 5360,\n",
              " 'by': 1293,\n",
              " 'michelangelo': 4910,\n",
              " 'bears': 871,\n",
              " 'his': 3700,\n",
              " 'signature': 6882,\n",
              " 'largest': 4345,\n",
              " 'snake': 6989,\n",
              " 'medium': 4850,\n",
              " 'stuart': 7297,\n",
              " 'hamblen': 3531,\n",
              " 'be': 861,\n",
              " 'internet': 3988,\n",
              " 'song': 7043,\n",
              " 'lyrics': 4603,\n",
              " 'database': 2143,\n",
              " 'similar': 6895,\n",
              " 'international': 3987,\n",
              " 'server': 6757,\n",
              " 'much': 5086,\n",
              " 'money': 5009,\n",
              " 'back': 764,\n",
              " 'injury': 3952,\n",
              " 'lawsuit': 4370,\n",
              " 'common': 1781,\n",
              " 'acetylsalicylic': 301,\n",
              " 'acid': 306,\n",
              " 'georgetown': 3317,\n",
              " 'hoya': 3789,\n",
              " 'classic': 1642,\n",
              " 'books': 1094,\n",
              " '5th': 227,\n",
              " '6th': 232,\n",
              " 'graders': 3429,\n",
              " 'should': 6852,\n",
              " 'read': 6224,\n",
              " 'products': 6014,\n",
              " 'use': 7926,\n",
              " 'tiger': 7643,\n",
              " 'their': 7582,\n",
              " 'symbol': 7422,\n",
              " 'election': 2628,\n",
              " 'pope': 5872,\n",
              " 'announced': 541,\n",
              " 'long': 4541,\n",
              " 'your': 8381,\n",
              " 'blood': 1047,\n",
              " 'complete': 1804,\n",
              " 'trip': 7793,\n",
              " 'through': 7626,\n",
              " 'chickens': 1562,\n",
              " 'have': 3586,\n",
              " 'baby': 761,\n",
              " 'chicks': 1563,\n",
              " 'historical': 3702,\n",
              " 'catholic': 1447,\n",
              " 'church': 1610,\n",
              " 'bingo': 995,\n",
              " 'element': 2636,\n",
              " 'calcium': 1315,\n",
              " 'named': 5143,\n",
              " 'crooner': 2047,\n",
              " 'joined': 4142,\n",
              " 'andrews': 516,\n",
              " 'sisters': 6924,\n",
              " 'pistol': 5769,\n",
              " 'packin': 5520,\n",
              " 'mama': 4681,\n",
              " 'piano': 5729,\n",
              " 'claims': 1637,\n",
              " 'its': 4057,\n",
              " 'product': 6012,\n",
              " 'instrument': 3975,\n",
              " 'immortals': 3870,\n",
              " 'mutiny': 5119,\n",
              " 'novel': 5317,\n",
              " 'movie': 5074,\n",
              " 'bladerunner': 1027,\n",
              " 'transistor': 7751,\n",
              " 'film': 3007,\n",
              " 'starring': 7184,\n",
              " 'jude': 4168,\n",
              " 'law': 4365,\n",
              " 'hollywood': 3727,\n",
              " 'dog': 2404,\n",
              " 'arms': 636,\n",
              " 'jean': 4092,\n",
              " 'harlow': 3566,\n",
              " '1932': 100,\n",
              " 'elements': 2637,\n",
              " 'earth': 2556,\n",
              " 'crust': 2064,\n",
              " 'cost': 1954,\n",
              " 'purchase': 6096,\n",
              " 'foot': 3110,\n",
              " 'square': 7151,\n",
              " 'party': 5590,\n",
              " 'tent': 7536,\n",
              " 'sides': 6874,\n",
              " 'actress': 326,\n",
              " 'received': 6243,\n",
              " 'oscar': 5460,\n",
              " 'nominations': 5284,\n",
              " 'equity': 2738,\n",
              " 'securities': 6709,\n",
              " 'gymnophobia': 3511,\n",
              " 'years': 8353,\n",
              " 'fossils': 3149,\n",
              " 'orinoco': 5452,\n",
              " 'little': 4508,\n",
              " 'rascals': 6204,\n",
              " 'penn': 5650,\n",
              " 'landing': 4330,\n",
              " 'banks': 806,\n",
              " 'delaware': 2210,\n",
              " 'broadway': 1194,\n",
              " 'musical': 5111,\n",
              " 'cervantes': 1495,\n",
              " 'don': 2423,\n",
              " 'quixote': 6150,\n",
              " 'jj': 4124,\n",
              " 'hostages': 3769,\n",
              " 'entebbe': 2713,\n",
              " 'raid': 6172,\n",
              " 'raise': 6183,\n",
              " 'iq': 4019,\n",
              " 'inri': 3960,\n",
              " 'cross': 2050,\n",
              " 'produces': 6010,\n",
              " 'spumante': 7148,\n",
              " 'earns': 2554,\n",
              " 'hard': 3561,\n",
              " 'way': 8135,\n",
              " 'founded': 3155,\n",
              " 'temple': 7526,\n",
              " 'commune': 1785,\n",
              " 'athlete': 693,\n",
              " 'makes': 4668,\n",
              " 'sports': 7132,\n",
              " 'merchandise': 4879,\n",
              " 'sales': 6578,\n",
              " 'bends': 931,\n",
              " 'standard': 7175,\n",
              " 'clip': 1665,\n",
              " 'discovered': 2356,\n",
              " 'electricity': 2633,\n",
              " 'contains': 1882,\n",
              " 'american': 491,\n",
              " 'space': 7069,\n",
              " 'south': 7061,\n",
              " 'countries': 1973,\n",
              " 'border': 1103,\n",
              " 'brazil': 1160,\n",
              " 'album': 428,\n",
              " 'put': 6111,\n",
              " 'beatles': 877,\n",
              " 'cover': 1986,\n",
              " 'time': 7647,\n",
              " '1967': 135,\n",
              " 'poem': 5824,\n",
              " 'line': 4481,\n",
              " 'grow': 3479,\n",
              " 'me': 4827,\n",
              " 'best': 959,\n",
              " 'yet': 8361,\n",
              " 'dental': 2227,\n",
              " 'root': 6499,\n",
              " 'canal': 1354,\n",
              " 'war': 8100,\n",
              " 'wan': 8095,\n",
              " 'na': 5133,\n",
              " 'riots': 6437,\n",
              " 'occur': 5354,\n",
              " 'busiest': 1275,\n",
              " 'air': 407,\n",
              " 'season': 6694,\n",
              " 'colored': 1742,\n",
              " 'eye': 2865,\n",
              " 'hook': 3748,\n",
              " 'worms': 8308,\n",
              " 'rose': 6504,\n",
              " 'bowl': 1131,\n",
              " 'played': 5801,\n",
              " 'japanese': 4082,\n",
              " 'car': 1387,\n",
              " 'maker': 4667,\n",
              " 'had': 3517,\n",
              " 'biggest': 983,\n",
              " 'percentage': 5661,\n",
              " 'sale': 6577,\n",
              " 'domestic': 2416,\n",
              " 'market': 4738,\n",
              " 'mayor': 4812,\n",
              " 'marbella': 4718,\n",
              " 'sun': 7345,\n",
              " 'blasted': 1032,\n",
              " '14': 18,\n",
              " 'mile': 4935,\n",
              " 'wide': 8209,\n",
              " 'valley': 7947,\n",
              " 'just': 4188,\n",
              " 'north': 5301,\n",
              " 'mojave': 4998,\n",
              " 'desert': 2247,\n",
              " 'thatcher': 7575,\n",
              " 'prime': 5978,\n",
              " 'minister': 4966,\n",
              " 'months': 5025,\n",
              " 'moon': 5030,\n",
              " 'revolve': 6397,\n",
              " 'around': 641,\n",
              " '49': 216,\n",
              " 'steps': 7222,\n",
              " 'gaulle': 3291,\n",
              " 'elected': 2627,\n",
              " 'president': 5956,\n",
              " 'france': 3168,\n",
              " 'sings': 6911,\n",
              " 'themes': 7585,\n",
              " 'dawson': 2153,\n",
              " 'creek': 2028,\n",
              " 'felicity': 2963,\n",
              " 'directed': 2338,\n",
              " 'jaws': 4085,\n",
              " 'show': 6856,\n",
              " 'could': 1964,\n",
              " 'tom': 7677,\n",
              " 'terrific': 7547,\n",
              " 'indian': 3911,\n",
              " 'tribe': 7784,\n",
              " 'troop': 7801,\n",
              " 'perpetually': 5678,\n",
              " 'doing': 2408,\n",
              " 'battle': 853,\n",
              " 'pudding': 6080,\n",
              " 'some': 7034,\n",
              " 'labels': 4308,\n",
              " 'say': 6628,\n",
              " 'nonchlorine': 5288,\n",
              " 'bleach': 1034,\n",
              " 'colonies': 1737,\n",
              " 'involved': 4012,\n",
              " 'revolution': 6393,\n",
              " 'maurizio': 4800,\n",
              " 'pellegrin': 5637,\n",
              " 'lives': 4513,\n",
              " 'pictorial': 5739,\n",
              " 'directions': 2340,\n",
              " 'build': 1233,\n",
              " 'very': 7995,\n",
              " 'simple': 6897,\n",
              " 'treehouse': 7778,\n",
              " 'board': 1058,\n",
              " 'shows': 6861,\n",
              " 'territories': 7549,\n",
              " 'irkutsk': 4028,\n",
              " 'yakutsk': 8341,\n",
              " 'kamchatka': 4196,\n",
              " 'managing': 4687,\n",
              " 'director': 2342,\n",
              " 'apricot': 601,\n",
              " 'computer': 1814,\n",
              " 'occupation': 5352,\n",
              " 'nicholas': 5241,\n",
              " 'cage': 1311,\n",
              " 'horseshoes': 3764,\n",
              " 'bring': 1187,\n",
              " 'luck': 4582,\n",
              " '401': 206,\n",
              " 'plan': 5787,\n",
              " 'pneumonia': 5819,\n",
              " 'three': 7621,\n",
              " 'winter': 8256,\n",
              " 'southern': 7064,\n",
              " 'hemisphere': 3645,\n",
              " 'gringo': 3471,\n",
              " 'africa': 380,\n",
              " 'northernmost': 5303,\n",
              " 'therapy': 7594,\n",
              " 'attempts': 705,\n",
              " 'elicit': 2644,\n",
              " 'primal': 5975,\n",
              " 'scream': 6672,\n",
              " 'kalahari': 4195,\n",
              " 'ventura': 7979,\n",
              " 'county': 1975,\n",
              " 'police': 5842,\n",
              " 'department': 2231,\n",
              " 'seized': 6720,\n",
              " 'cocaine': 1700,\n",
              " 'shipment': 6827,\n",
              " 'gotham': 3412,\n",
              " 'dangles': 2124,\n",
              " 'tongue': 7680,\n",
              " 'palate': 5542,\n",
              " 'created': 2017,\n",
              " 'dennis': 2224,\n",
              " 'menace': 4871,\n",
              " 'dummy': 2522,\n",
              " 'honorary': 3744,\n",
              " 'degree': 2208,\n",
              " 'northwestern': 5304,\n",
              " 'university': 7895,\n",
              " 'wall': 8089,\n",
              " 'street': 7276,\n",
              " 'journal': 4157,\n",
              " 'published': 6077,\n",
              " 'areas': 624,\n",
              " 'forest': 3128,\n",
              " 'start': 7187,\n",
              " 'web': 8150,\n",
              " 'based': 833,\n",
              " 'business': 1276,\n",
              " 'alvin': 473,\n",
              " 'eagle': 2547,\n",
              " 'syndrome': 7428,\n",
              " 'styloid': 7306,\n",
              " 'process': 6002,\n",
              " 'jayne': 4087,\n",
              " 'mansfield': 4704,\n",
              " 'die': 2308,\n",
              " 'royal': 6524,\n",
              " 'wedding': 8156,\n",
              " 'prince': 5980,\n",
              " 'andrew': 515,\n",
              " 'fergie': 2972,\n",
              " 'actor': 324,\n",
              " 'said': 6569,\n",
              " 'races': 6160,\n",
              " 'either': 2619,\n",
              " 'dead': 2163,\n",
              " 'watch': 8121,\n",
              " 'stopped': 7255,\n",
              " 'explorer': 2843,\n",
              " 'nicknamed': 5245,\n",
              " 'iberia': 3841,\n",
              " 'pilot': 5756,\n",
              " 'began': 902,\n",
              " 'ball': 789,\n",
              " 'hits': 3707,\n",
              " 'foul': 3152,\n",
              " 'pole': 5841,\n",
              " 'hamburgers': 3533,\n",
              " 'taste': 7479,\n",
              " 'like': 4466,\n",
              " 'steakburgers': 7208,\n",
              " 'browser': 1209,\n",
              " 'mosaic': 5046,\n",
              " 'rites': 6446,\n",
              " 'accompanying': 296,\n",
              " 'circumcision': 1622,\n",
              " 'newly': 5227,\n",
              " 'child': 1569,\n",
              " 'judaism': 4167,\n",
              " 'education': 2597,\n",
              " '1960': 127,\n",
              " 'commercial': 1773,\n",
              " 'field': 2992,\n",
              " 'cities': 1628,\n",
              " 'cable': 1301,\n",
              " 'modem': 4994,\n",
              " 'access': 290,\n",
              " 'betsy': 964,\n",
              " 'ross': 6507,\n",
              " 'sharks': 6796,\n",
              " 'snoogans': 6998,\n",
              " 'shrubs': 6864,\n",
              " 'planted': 5795,\n",
              " 'will': 8225,\n",
              " 'safe': 6564,\n",
              " 'deer': 2195,\n",
              " 'organization': 5440,\n",
              " 'offices': 5377,\n",
              " 'broken': 1197,\n",
              " 'watergate': 8127,\n",
              " '1972': 141,\n",
              " 'design': 2249,\n",
              " 'ship': 6826,\n",
              " 'titanic': 7657,\n",
              " 'technique': 7501,\n",
              " 'widely': 8210,\n",
              " 'detect': 2264,\n",
              " 'birth': 1006,\n",
              " 'defects': 2199,\n",
              " 'daily': 2105,\n",
              " 'requirement': 6351,\n",
              " 'folic': 3096,\n",
              " 'expectant': 2832,\n",
              " 'mother': 5055,\n",
              " 'minute': 4972,\n",
              " 'cigarette': 1615,\n",
              " 'forms': 3139,\n",
              " 'gold': 3387,\n",
              " 'acreage': 313,\n",
              " 'chappellet': 1521,\n",
              " 'vineyard': 8030,\n",
              " 'correctly': 1945,\n",
              " 'qigong': 6120,\n",
              " 'beethoven': 898,\n",
              " 'railroad': 6176,\n",
              " 'coal': 1690,\n",
              " 'entered': 2715,\n",
              " 'independence': 3908,\n",
              " 'against': 387,\n",
              " 'british': 1190,\n",
              " 'filmmakers': 3008,\n",
              " 'collabrative': 1721,\n",
              " 'russian': 6554,\n",
              " 'composer': 1808,\n",
              " 'prelude': 5943,\n",
              " 'sharp': 6798,\n",
              " 'minor': 4969,\n",
              " 'brought': 1206,\n",
              " 'him': 3694,\n",
              " 'fame': 2898,\n",
              " 'fortune': 3146,\n",
              " 'caused': 1456,\n",
              " 'harry': 3573,\n",
              " 'houdini': 3773,\n",
              " 'death': 2174,\n",
              " 'duke': 2517,\n",
              " 'windsor': 8241,\n",
              " 'revolutions': 6396,\n",
              " 'lp': 4576,\n",
              " 'minutes': 4973,\n",
              " 'tallest': 7465,\n",
              " 'mountain': 5064,\n",
              " 'review': 6388,\n",
              " 'nightmare': 5254,\n",
              " 'elm': 2653,\n",
              " 'slowest': 6972,\n",
              " 'swimming': 7413,\n",
              " 'stroke': 7289,\n",
              " 'astronaut': 685,\n",
              " 'spacewalk': 7073,\n",
              " 'disease': 2357,\n",
              " 'transmitted': 7757,\n",
              " 'anopheles': 543,\n",
              " 'mosquito': 5049,\n",
              " 'rum': 6542,\n",
              " 'so': 7009,\n",
              " 'mixable': 4987,\n",
              " 'brand': 1153,\n",
              " 'bar': 809,\n",
              " 'letter': 4432,\n",
              " 'contents': 1886,\n",
              " 'proposition': 6044,\n",
              " '98': 254,\n",
              " 'george': 3316,\n",
              " 'washington': 8116,\n",
              " 'ground': 3475,\n",
              " 'bombing': 1085,\n",
              " 'pan': 5553,\n",
              " 'am': 476,\n",
              " 'flight': 3064,\n",
              " '103': 5,\n",
              " 'lockerbie': 4529,\n",
              " 'scotland': 6665,\n",
              " 'december': 2182,\n",
              " '21': 179,\n",
              " 'wrote': 8328,\n",
              " 'nn': 5272,\n",
              " 'dt': 2504,\n",
              " 'paracetamol': 5566,\n",
              " 'powers': 5922,\n",
              " 'weaknesses': 8142,\n",
              " 'green': 3457,\n",
              " 'lantern': 4338,\n",
              " 'ring': 6433,\n",
              " 'bite': 1016,\n",
              " 'draws': 2474,\n",
              " 'cc': 1464,\n",
              " 'steel': 7213,\n",
              " 'mill': 4941,\n",
              " 'built': 1239,\n",
              " 'diminutive': 2324,\n",
              " 'gymnast': 3509,\n",
              " '1984': 155,\n",
              " 'olympics': 5401,\n",
              " 'katie': 4210,\n",
              " 'schools': 6650,\n",
              " 'dc': 2160,\n",
              " 'vbp': 7964,\n",
              " 'berlin': 944,\n",
              " 'terrence': 7544,\n",
              " 'malick': 4676,\n",
              " 'ray': 6214,\n",
              " 'charles': 1530,\n",
              " 'playing': 5804,\n",
              " 'latin': 4356,\n",
              " 'cry': 2065,\n",
              " 'ad': 329,\n",
              " 'arma': 633,\n",
              " 'mascot': 4770,\n",
              " 'notre': 5314,\n",
              " 'dame': 2113,\n",
              " 'las': 4348,\n",
              " 'vegas': 7969,\n",
              " 'hotel': 3772,\n",
              " 'burned': 1265,\n",
              " 'november': 5320,\n",
              " '1980': 150,\n",
              " 'loss': 4555,\n",
              " '84': 244,\n",
              " 'mount': 5063,\n",
              " 'helen': 3634,\n",
              " 'last': 4350,\n",
              " 'significant': 6884,\n",
              " 'eruption': 2756,\n",
              " 'fathom': 2935,\n",
              " 'canada': 1351,\n",
              " 'penny': 5653,\n",
              " 'black': 1021,\n",
              " 'nicois': 5246,\n",
              " 'beanie': 865,\n",
              " 'introduced': 3998,\n",
              " 'tragic': 7742,\n",
              " 'hero': 3668,\n",
              " 'microsoft': 4918,\n",
              " 'windows': 8238,\n",
              " 'owe': 5496,\n",
              " 'success': 7322,\n",
              " 'afghanistan': 377,\n",
              " '1994': 165,\n",
              " 'other': 5468,\n",
              " 'ways': 8138,\n",
              " 'getting': 3330,\n",
              " 'stretch': 7279,\n",
              " 'marks': 4741,\n",
              " 'besides': 957,\n",
              " 'pregnancy': 5940,\n",
              " 'weight': 8163,\n",
              " 'lifting': 4460,\n",
              " 'brontosauruses': 1198,\n",
              " 'eat': 2567,\n",
              " 'bottles': 1118,\n",
              " 'good': 3401,\n",
              " 'rhine': 6402,\n",
              " 'wines': 8243,\n",
              " 'lead': 4378,\n",
              " 'sleepless': 6959,\n",
              " 'seattle': 6698,\n",
              " '16th': 34,\n",
              " 'sons': 7048,\n",
              " 'ozzie': 5514,\n",
              " 'harriet': 3571,\n",
              " 'nelson': 5203,\n",
              " 'molybdenum': 5002,\n",
              " 'lowest': 4574,\n",
              " 'level': 4436,\n",
              " 'judiciary': 4171,\n",
              " 'somme': 7040,\n",
              " 'fought': 3151,\n",
              " 'randy': 6193,\n",
              " 'craft': 2004,\n",
              " 'kill': 4242,\n",
              " 'official': 5378,\n",
              " 'animal': 529,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train and test an svm with sigmoid as kernel function and the following parametres..."
      ],
      "metadata": {
        "id": "DD49D-IIh7xI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "c = 1.5\n",
        "decision_function='ovr'\n",
        "max_iter=-1\n",
        "kernel='sigmoid'\n",
        "degree=2\n",
        "gamma =1.0\n",
        "\n",
        "svm_sig = SVC(C=c, max_iter=max_iter, degree=degree, kernel=kernel, gamma=gamma, decision_function_shape=decision_function)\n",
        "\n",
        "svm_sig.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "2QFuD8e8iDfX",
        "outputId": "b3ad8be7-6cea-4171-d04c-217410456bde"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.5, degree=2, gamma=1.0, kernel='sigmoid')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1.5, degree=2, gamma=1.0, kernel=&#x27;sigmoid&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1.5, degree=2, gamma=1.0, kernel=&#x27;sigmoid&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the svm model on the test set and evaluate it..."
      ],
      "metadata": {
        "id": "-0cyxnh8lVEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svm_sig.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j76eHcCPfjIs",
        "outputId": "4ba462a5-4086-4c57-8478-0b5d04e7f689"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ABBR       1.00      0.78      0.88         9\n",
            "        DESC       0.84      0.99      0.91       138\n",
            "        ENTY       0.83      0.71      0.77        94\n",
            "         HUM       0.88      0.91      0.89        65\n",
            "         LOC       0.87      0.85      0.86        81\n",
            "         NUM       0.99      0.90      0.94       113\n",
            "\n",
            "    accuracy                           0.88       500\n",
            "   macro avg       0.90      0.86      0.88       500\n",
            "weighted avg       0.89      0.88      0.88       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train and test a Multinomial Naive Bayes with alpha's parameter equal to 0.1..."
      ],
      "metadata": {
        "id": "YJCmGfwwilVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "MultinomialNB_model = MultinomialNB(alpha=0.1)\n",
        "MultinomialNB_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "88Zb2s65iZiS",
        "outputId": "6c8db553-5971-47cf-c530-e74630515592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.1)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the MultinomialNB model on the test set and evaluate it..."
      ],
      "metadata": {
        "id": "OMn2Wf8XmG4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = MultinomialNB_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HExNf4mjl7Mu",
        "outputId": "89cfff1f-66c2-4775-a91c-eecb8896ef64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ABBR       1.00      0.67      0.80         9\n",
            "        DESC       0.81      0.83      0.82       138\n",
            "        ENTY       0.73      0.59      0.65        94\n",
            "         HUM       0.65      0.89      0.75        65\n",
            "         LOC       0.66      0.77      0.71        81\n",
            "         NUM       0.89      0.74      0.81       113\n",
            "\n",
            "    accuracy                           0.76       500\n",
            "   macro avg       0.79      0.75      0.76       500\n",
            "weighted avg       0.77      0.76      0.76       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: both SVM's and MultinomialNB's parameters are choosen by looking the previous exercises since they were found to be the best on Question Classification Task.\n",
        "\n",
        "Looking at the results it seems that SVM performs better than MultinomialNB"
      ],
      "metadata": {
        "id": "WjBKUIFPjY9p"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weiliphYDwYh"
      },
      "source": [
        "### Exercise 4: Replace texts with entities\n",
        "\n",
        "For every sentence in the QuestionClassification dataset, extract the entities annotated by the spacy module only for the proper nouns (`PROPN`) and replace the spans in the text with the entity name:\n",
        "\n",
        "- Sentence: '*In 1982, Mark drove his car from Los Angeles to Las Vegas until 5 of july*'  \n",
        "- Modified Sentence: '*In 1982, PERSON drove his car from GPE to GPE until 5 of DATE*'\n",
        "\n",
        "Store the enriched sentences in a new dataframe and train a classifier (SVM, NB, Rocchio..) and evaluate it.\n",
        "\n",
        "**WARNING**: be careful with `compounds`, they should be replaced by a SINGLE entity name: *Las Vegas* => `GPE`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "annotated_sentence = get_sentence_annotation(\"In 1982, Mark drove his car from Los Angeles to Las Vegas until 5 of july\")\n",
        "annotated_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PYGjObzp6iF",
        "outputId": "b67f19e3-bd8e-42f9-f088-a6929b010506"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 1,\n",
              "  'word': 'In',\n",
              "  'lemma': 'in',\n",
              "  'tag': 'IN',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'prep',\n",
              "  'head_id': 5},\n",
              " {'id': 2,\n",
              "  'word': '1982',\n",
              "  'lemma': '1982',\n",
              "  'tag': 'CD',\n",
              "  'entity': 'DATE',\n",
              "  'dependency': 'pobj',\n",
              "  'head_id': 1},\n",
              " {'id': 3,\n",
              "  'word': ',',\n",
              "  'lemma': ',',\n",
              "  'tag': ',',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'punct',\n",
              "  'head_id': 5},\n",
              " {'id': 4,\n",
              "  'word': 'Mark',\n",
              "  'lemma': 'Mark',\n",
              "  'tag': 'NNP',\n",
              "  'entity': 'PERSON',\n",
              "  'dependency': 'nsubj',\n",
              "  'head_id': 5},\n",
              " {'id': 5,\n",
              "  'word': 'drove',\n",
              "  'lemma': 'drive',\n",
              "  'tag': 'VBD',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'ROOT',\n",
              "  'head_id': 0},\n",
              " {'id': 6,\n",
              "  'word': 'his',\n",
              "  'lemma': 'his',\n",
              "  'tag': 'PRP$',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'poss',\n",
              "  'head_id': 7},\n",
              " {'id': 7,\n",
              "  'word': 'car',\n",
              "  'lemma': 'car',\n",
              "  'tag': 'NN',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'dobj',\n",
              "  'head_id': 5},\n",
              " {'id': 8,\n",
              "  'word': 'from',\n",
              "  'lemma': 'from',\n",
              "  'tag': 'IN',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'prep',\n",
              "  'head_id': 5},\n",
              " {'id': 9,\n",
              "  'word': 'Los',\n",
              "  'lemma': 'Los',\n",
              "  'tag': 'NNP',\n",
              "  'entity': 'GPE',\n",
              "  'dependency': 'compound',\n",
              "  'head_id': 10},\n",
              " {'id': 10,\n",
              "  'word': 'Angeles',\n",
              "  'lemma': 'Angeles',\n",
              "  'tag': 'NNP',\n",
              "  'entity': 'GPE',\n",
              "  'dependency': 'pobj',\n",
              "  'head_id': 8},\n",
              " {'id': 11,\n",
              "  'word': 'to',\n",
              "  'lemma': 'to',\n",
              "  'tag': 'IN',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'prep',\n",
              "  'head_id': 5},\n",
              " {'id': 12,\n",
              "  'word': 'Las',\n",
              "  'lemma': 'Las',\n",
              "  'tag': 'NNP',\n",
              "  'entity': 'GPE',\n",
              "  'dependency': 'compound',\n",
              "  'head_id': 13},\n",
              " {'id': 13,\n",
              "  'word': 'Vegas',\n",
              "  'lemma': 'Vegas',\n",
              "  'tag': 'NNP',\n",
              "  'entity': 'GPE',\n",
              "  'dependency': 'pobj',\n",
              "  'head_id': 11},\n",
              " {'id': 14,\n",
              "  'word': 'until',\n",
              "  'lemma': 'until',\n",
              "  'tag': 'IN',\n",
              "  'entity': 'O',\n",
              "  'dependency': 'prep',\n",
              "  'head_id': 5},\n",
              " {'id': 15,\n",
              "  'word': '5',\n",
              "  'lemma': '5',\n",
              "  'tag': 'CD',\n",
              "  'entity': 'DATE',\n",
              "  'dependency': 'pobj',\n",
              "  'head_id': 14},\n",
              " {'id': 16,\n",
              "  'word': 'of',\n",
              "  'lemma': 'of',\n",
              "  'tag': 'IN',\n",
              "  'entity': 'DATE',\n",
              "  'dependency': 'prep',\n",
              "  'head_id': 15},\n",
              " {'id': 17,\n",
              "  'word': 'july',\n",
              "  'lemma': 'july',\n",
              "  'tag': 'NNP',\n",
              "  'entity': 'DATE',\n",
              "  'dependency': 'pobj',\n",
              "  'head_id': 16}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_relation(input_string,\"compound\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpw7g5cPgT71",
        "outputId": "42defad3-8163-4c92-c94c-8bed8daa8e8a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[10, 9], [13, 12]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.util import get_words_and_spaces\n",
        "#this function takes in input a sentence \n",
        "#after annotating it with spacy it replace proper nouns with the associated entity\n",
        "\n",
        "def get_enriched_sentence_with_entity(sentence): \n",
        "    annotated_sentence = get_sentence_annotation(sentence)\n",
        "    enriched_sentence_list = []\n",
        "    \n",
        "    i=0\n",
        "    l=len(annotated_sentence)\n",
        "    while i < len(annotated_sentence):\n",
        "      if(annotated_sentence[i][\"tag\"]==\"NNP\"):\n",
        "        enriched_sentence_list.append(annotated_sentence[i][\"entity\"])\n",
        "        if(annotated_sentence[i][\"dependency\"]==\"compound\"):\n",
        "          i+=2\n",
        "        else:\n",
        "          i+=1\n",
        "      else:\n",
        "        enriched_sentence_list.append(annotated_sentence[i][\"word\"])\n",
        "        i+=1\n",
        "      \n",
        "    #now get the enriched text (NOTE: we want to tokenize togethere head and tail of the relation)!\n",
        "    enriched_sentence=''\n",
        "\n",
        "    enriched_sentence= \" \".join(enriched_sentence_list)\n",
        "\n",
        "    return enriched_sentence"
      ],
      "metadata": {
        "id": "v08SFFQ3o9ko"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_enriched_sentence_with_entity(\"Marc is going to Las Palmas with the Harley Davidson\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3RUCk4yrQ5BX",
        "outputId": "d1dc9ea5-b8a5-48e4-fb7b-ee8849dc01c1"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PERSON is going to GPE with the ORG'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_enriched_sentence_with_entity(\"In 1982, Mark drove his car from Los Angeles to Las Vegas until 5 of july\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "RiTXjGXB4K8v",
        "outputId": "99b3c95e-e0e2-4acf-cccc-6a90825629bc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ao\n",
            "ao\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In 1982 , drove his car from GPE to GPE until 5 of'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's enrich all the dataset\n",
        "\n",
        "train_enriched_questions=[]\n",
        "test_enriched_questions=[]\n",
        "\n",
        "for question in train_questions:\n",
        "  train_enriched_questions.append(get_enriched_sentence_with_entity(question))\n",
        "\n",
        "for question in test_questions:\n",
        "  test_enriched_questions.append(get_enriched_sentence_with_entity(question))\n"
      ],
      "metadata": {
        "id": "Na3-YNh4lGPy"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize the dataset and store it inside the dataframe\n",
        "#NOTE: do note remove stopwords like \"?\" ,\"!\",\":\" \n",
        "#In particulare words surrounded by \"#\" witness a dependency relation inside the sentence which can be usefull for our task\n",
        "nltk.download('punkt')\n",
        "\n",
        "training_data['enriched_questions_entity'] = list(map(lambda sent: nltk.word_tokenize(sent), train_enriched_questions))\n",
        "testing_data['enriched_questions_entity'] = list(map(lambda sent: nltk.word_tokenize(sent), test_enriched_questions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEI1CYDLmLH-",
        "outputId": "06e7a3b1-a18d-4247-bc12-bfabf069ea40"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#transforming list of token into a string...\n",
        "#\" \".join(str(x) for x in xs)\n",
        "training_data[\"enriched_questions_entity\"] = training_data[\"enriched_questions_entity\"].apply(lambda l: ' '.join(str(t) for t in l))\n",
        "testing_data[\"enriched_questions_entity\"] = testing_data[\"enriched_questions_entity\"].apply(lambda l: ' '.join(str(t) for t in l))"
      ],
      "metadata": {
        "id": "13hWe5rqoBqc"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: using BOW-vectorizer we are losing informations about the position of a word inside the sentence\n",
        "# hence we are partially losing the informations we have encoded before (like the head and tail of a dependecy relation)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(training_data['enriched_questions_entity'].tolist())\n",
        "X_test = vectorizer.transform(testing_data['enriched_questions_entity'].tolist())\n",
        "y_train = training_data['classes'].tolist()\n",
        "y_test = testing_data['classes'].tolist()"
      ],
      "metadata": {
        "id": "Fc8JdPc2mfHL"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now inside the vocabulary we have also named_entity\n",
        "\n",
        "vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEw_PmNemljh",
        "outputId": "fb2cb5b4-caf3-4637-e2eb-88cb717466ab"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'how': 2723,\n",
              " 'did': 1691,\n",
              " 'serfdom': 4671,\n",
              " 'develop': 1666,\n",
              " 'in': 2789,\n",
              " 'and': 440,\n",
              " 'then': 5319,\n",
              " 'leave': 3070,\n",
              " 'gpe': 2490,\n",
              " 'what': 5757,\n",
              " 'films': 2215,\n",
              " 'featured': 2176,\n",
              " 'the': 5310,\n",
              " 'character': 1103,\n",
              " 'person': 3882,\n",
              " 'can': 984,\n",
              " 'find': 2220,\n",
              " 'list': 3141,\n",
              " 'of': 3658,\n",
              " 'celebrities': 1064,\n",
              " 'real': 4302,\n",
              " 'names': 3519,\n",
              " 'fowl': 2337,\n",
              " 'grabs': 2492,\n",
              " 'spotlight': 4971,\n",
              " 'after': 354,\n",
              " 'event': 2049,\n",
              " 'product': 4129,\n",
              " 'is': 2904,\n",
              " 'full': 2371,\n",
              " 'form': 2315,\n",
              " 'com': 1255,\n",
              " 'contemptible': 1375,\n",
              " 'scoundrel': 4608,\n",
              " 'stole': 5054,\n",
              " 'cork': 1415,\n",
              " 'from': 2362,\n",
              " 'my': 3507,\n",
              " 'lunch': 3199,\n",
              " 'team': 5252,\n",
              " 'baseball': 644,\n",
              " 'fac': 2117,\n",
              " 'browns': 888,\n",
              " 'become': 679,\n",
              " 'oldest': 3676,\n",
              " 'profession': 4132,\n",
              " 'are': 511,\n",
              " 'liver': 3154,\n",
              " 'enzymes': 2007,\n",
              " 'name': 3517,\n",
              " 'scar': 4587,\n",
              " 'faced': 2119,\n",
              " 'bounty': 833,\n",
              " 'hunter': 2736,\n",
              " 'org': 3713,\n",
              " 'when': 5761,\n",
              " 'was': 5704,\n",
              " 'born': 820,\n",
              " 'why': 5776,\n",
              " 'do': 1766,\n",
              " 'heavier': 2619,\n",
              " 'objects': 3639,\n",
              " 'travel': 5464,\n",
              " 'downhill': 1808,\n",
              " 'faster': 2159,\n",
              " 'who': 5769,\n",
              " 'work_of_art': 5828,\n",
              " 'yankees': 5859,\n",
              " 'killed': 2988,\n",
              " 'considered': 1355,\n",
              " 'costliest': 1428,\n",
              " 'disaster': 1728,\n",
              " 'insurance': 2862,\n",
              " 'industry': 2819,\n",
              " 'has': 2585,\n",
              " 'ever': 2051,\n",
              " 'sprawling': 4974,\n",
              " 'boasts': 793,\n",
              " 'most': 3456,\n",
              " 'airports': 385,\n",
              " 'only': 3688,\n",
              " 'repealed': 4391,\n",
              " 'amendment': 424,\n",
              " 'to': 5377,\n",
              " 'deal': 1581,\n",
              " 'with': 5807,\n",
              " 'many': 3260,\n",
              " 'jews': 2943,\n",
              " 'were': 5749,\n",
              " 'executed': 2070,\n",
              " 'concentration': 1319,\n",
              " 'camps': 983,\n",
              " 'during': 1860,\n",
              " 'nine': 3585,\n",
              " 'an': 434,\n",
              " 'annotated': 452,\n",
              " 'bibliography': 730,\n",
              " 'date': 1567,\n",
              " 'boxing': 845,\n",
              " 'articles': 530,\n",
              " 'clothing': 1209,\n",
              " 'tokens': 5383,\n",
              " '11': 6,\n",
              " 'famous': 2143,\n",
              " 'martyrs': 3284,\n",
              " 'olympic': 3679,\n",
              " 'motto': 3463,\n",
              " 'origin': 3724,\n",
              " 'second': 4637,\n",
              " 'used': 5582,\n",
              " 'vowel': 5680,\n",
              " 'language': 3028,\n",
              " 'inventor': 2891,\n",
              " 'silly': 4776,\n",
              " 'putty': 4215,\n",
              " 'highest': 2655,\n",
              " 'waterfall': 5715,\n",
              " 'golf': 2474,\n",
              " 'course': 1449,\n",
              " 'which': 5763,\n",
              " 'two': 5530,\n",
              " 'states': 5019,\n",
              " 'enclose': 1967,\n",
              " 'loc': 3161,\n",
              " 'does': 1771,\n",
              " 'abbreviation': 261,\n",
              " 'stand': 5000,\n",
              " 'for': 2300,\n",
              " 'spermologer': 4948,\n",
              " 'collect': 1237,\n",
              " 'points': 3985,\n",
              " 'make': 3233,\n",
              " 'up': 5567,\n",
              " 'perfect': 3869,\n",
              " 'fivepin': 2244,\n",
              " 'bowling': 840,\n",
              " 'score': 4603,\n",
              " 'company': 1293,\n",
              " 'that': 5309,\n",
              " 'manufactures': 3258,\n",
              " 'video': 5637,\n",
              " 'game': 2394,\n",
              " 'hardware': 2582,\n",
              " 'sells': 4659,\n",
              " 'super': 5147,\n",
              " 'system': 5206,\n",
              " 'cards': 1017,\n",
              " 'there': 5324,\n",
              " 'mormons': 3451,\n",
              " 'believe': 702,\n",
              " 'neanderthal': 3537,\n",
              " 'man': 3244,\n",
              " 'live': 3152,\n",
              " 'religion': 4380,\n",
              " 'nature': 3533,\n",
              " 'goddess': 2465,\n",
              " 'where': 5762,\n",
              " 'adventures': 334,\n",
              " 'take': 5220,\n",
              " 'place': 3946,\n",
              " 'relative': 4371,\n",
              " 'racoon': 4254,\n",
              " 'sometimes': 4893,\n",
              " 'known': 3007,\n",
              " 'as': 534,\n",
              " 'cat': 1044,\n",
              " 'bear': 668,\n",
              " 'register': 4357,\n",
              " 'website': 5737,\n",
              " 'free': 2344,\n",
              " 'cash': 1039,\n",
              " 'conscious': 1347,\n",
              " 'first': 2238,\n",
              " 'drill': 1824,\n",
              " 'people': 3864,\n",
              " 'world': 5832,\n",
              " 'speak': 4928,\n",
              " 'inches': 2794,\n",
              " 'over': 3751,\n",
              " 'six': 4802,\n",
              " 'feet': 2183,\n",
              " 'they': 5327,\n",
              " 'or': 3706,\n",
              " 'choose': 1151,\n",
              " 'witnesses': 5811,\n",
              " 'execution': 2071,\n",
              " '1920s': 89,\n",
              " 'cowboy': 1458,\n",
              " 'star': 5004,\n",
              " 'rode': 4493,\n",
              " 'cocktail': 1224,\n",
              " 'inspired': 2856,\n",
              " 'write': 5849,\n",
              " 'book': 812,\n",
              " 'not': 3614,\n",
              " 'shaken': 4704,\n",
              " 'isps': 2910,\n",
              " 'exist': 2077,\n",
              " 'you': 5872,\n",
              " 'ask': 538,\n",
              " 'total': 5409,\n",
              " 'stranger': 5073,\n",
              " 'out': 3741,\n",
              " 'on': 3681,\n",
              " 'weapon': 5729,\n",
              " 'mythological': 3513,\n",
              " 'proficient': 4135,\n",
              " 'country': 1443,\n",
              " 'belong': 708,\n",
              " 'ethology': 2042,\n",
              " 'prophet': 4160,\n",
              " 'muslim': 3502,\n",
              " 'term': 5287,\n",
              " '86ed': 245,\n",
              " 'come': 1261,\n",
              " 'arch': 504,\n",
              " 'enemy': 1977,\n",
              " 'learning': 3068,\n",
              " 'color': 1250,\n",
              " 'wears': 5733,\n",
              " 'stage': 4991,\n",
              " 'young': 5873,\n",
              " 'fox': 2338,\n",
              " 'lived': 3153,\n",
              " 'under': 5548,\n",
              " 'flags': 2249,\n",
              " 'extended': 2102,\n",
              " 'definition': 1613,\n",
              " 'mean': 3316,\n",
              " 'would': 5839,\n",
              " 'one': 3683,\n",
              " 'paper': 3807,\n",
              " 'it': 2915,\n",
              " 'capital': 1002,\n",
              " 'titanium': 5372,\n",
              " 'next': 3576,\n",
              " 'door': 1796,\n",
              " 'city': 1173,\n",
              " 'relationship': 4370,\n",
              " 'sister': 4796,\n",
              " 'caldera': 964,\n",
              " 'get': 2431,\n",
              " 'calluses': 972,\n",
              " 'tourist': 5419,\n",
              " 'attractions': 577,\n",
              " 'reims': 4364,\n",
              " 'body': 798,\n",
              " 'water': 5714,\n",
              " 'flow': 2272,\n",
              " 'into': 2878,\n",
              " 'founder': 2331,\n",
              " 'footed': 2298,\n",
              " 'enters': 1998,\n",
              " 'house': 2717,\n",
              " 'history': 2669,\n",
              " 'skateboarding': 4806,\n",
              " 'starred': 5007,\n",
              " 'fuel': 2370,\n",
              " 'bricks': 870,\n",
              " 'recycled': 4337,\n",
              " 'newspaper': 3574,\n",
              " '19th': 170,\n",
              " 'century': 1079,\n",
              " 'painter': 3789,\n",
              " 'died': 1693,\n",
              " 'corpus': 1421,\n",
              " 'callosum': 970,\n",
              " 'part': 3817,\n",
              " 'log': 3167,\n",
              " 'home': 2685,\n",
              " 'page': 3780,\n",
              " 'at': 556,\n",
              " 'nazis': 3536,\n",
              " 'occupy': 3646,\n",
              " 'cd': 1059,\n",
              " 'valuable': 5595,\n",
              " 'resource': 4421,\n",
              " 'species': 4934,\n",
              " 'head': 2603,\n",
              " 'lice': 3107,\n",
              " 'nickname': 3579,\n",
              " 'state': 5016,\n",
              " 'domesticated': 1784,\n",
              " 'bird': 751,\n",
              " 'villi': 5645,\n",
              " 'found': 2329,\n",
              " 'small': 4840,\n",
              " 'intestine': 2876,\n",
              " 'rule': 4526,\n",
              " 'fear': 2170,\n",
              " 'shadows': 4700,\n",
              " 'five': 2243,\n",
              " 'year': 5862,\n",
              " 'excluded': 2066,\n",
              " 'begin': 694,\n",
              " 'broadcasting': 879,\n",
              " 'causes': 1056,\n",
              " 'shiver': 4732,\n",
              " 'cold': 1234,\n",
              " 'temperatures': 5274,\n",
              " 'bull': 908,\n",
              " 'markets': 3272,\n",
              " 'features': 2177,\n",
              " 'central': 1076,\n",
              " 'dew': 1677,\n",
              " 'point': 3983,\n",
              " 'meaning': 3317,\n",
              " 'logo': 3170,\n",
              " 'circle': 1164,\n",
              " 'cascade': 1036,\n",
              " 'painting': 3791,\n",
              " 'architecture': 509,\n",
              " 'flourish': 2271,\n",
              " 'national': 3527,\n",
              " 'passenger': 3828,\n",
              " 'rail': 4261,\n",
              " 'called': 968,\n",
              " 'invented': 2888,\n",
              " 'word': 5825,\n",
              " 'attic': 571,\n",
              " 'hair': 2552,\n",
              " 'kind': 2993,\n",
              " 'animals': 448,\n",
              " 'following': 2289,\n",
              " 'comprised': 1313,\n",
              " 'now': 3622,\n",
              " 'defunct': 1614,\n",
              " 'comic': 1267,\n",
              " 'champions': 1092,\n",
              " 'paintball': 3787,\n",
              " 'female': 2188,\n",
              " 'rabbit': 4245,\n",
              " 'go': 2458,\n",
              " 'work': 5827,\n",
              " 'he': 2602,\n",
              " 'drops': 1837,\n",
              " 'off': 3659,\n",
              " 'cartoon': 1033,\n",
              " 'series': 4674,\n",
              " 'four': 2335,\n",
              " 'oceans': 3652,\n",
              " 'by': 944,\n",
              " 'bears': 669,\n",
              " 'his': 2666,\n",
              " 'signature': 4768,\n",
              " 'largest': 3036,\n",
              " 'snake': 4849,\n",
              " 'medium': 3332,\n",
              " 'be': 664,\n",
              " 'singing': 4787,\n",
              " 'internet': 2872,\n",
              " 'song': 4895,\n",
              " 'lyrics': 3206,\n",
              " 'database': 1566,\n",
              " 'similar': 4779,\n",
              " 'much': 3480,\n",
              " 'money': 3434,\n",
              " 'back': 606,\n",
              " 'injury': 2841,\n",
              " 'lawsuit': 3053,\n",
              " 'common': 1285,\n",
              " 'classic': 1181,\n",
              " 'books': 813,\n",
              " '5th': 224,\n",
              " '6th': 229,\n",
              " 'graders': 2496,\n",
              " 'should': 4748,\n",
              " 'read': 4298,\n",
              " 'products': 4131,\n",
              " 'use': 5581,\n",
              " 'tiger': 5360,\n",
              " 'their': 5314,\n",
              " 'symbol': 5195,\n",
              " 'election': 1924,\n",
              " 'new': 3569,\n",
              " 'announced': 454,\n",
              " 'long': 3171,\n",
              " 'your': 5876,\n",
              " 'blood': 781,\n",
              " 'complete': 1305,\n",
              " 'trip': 5492,\n",
              " 'through': 5347,\n",
              " 'chickens': 1131,\n",
              " 'have': 2593,\n",
              " 'baby': 604,\n",
              " 'chicks': 1132,\n",
              " 'historical': 2667,\n",
              " 'bingo': 745,\n",
              " 'element': 1932,\n",
              " 'calcium': 961,\n",
              " 'named': 3518,\n",
              " 'crooner': 1502,\n",
              " 'joined': 2950,\n",
              " 'piano': 3910,\n",
              " 'claims': 1179,\n",
              " 'its': 2920,\n",
              " 'instrument': 2860,\n",
              " 'immortals': 2773,\n",
              " 'novel': 3619,\n",
              " 'movie': 3475,\n",
              " 'transistor': 5453,\n",
              " 'film': 2213,\n",
              " 'starring': 5008,\n",
              " 'arms': 519,\n",
              " '1932': 100,\n",
              " 'elements': 1933,\n",
              " 'crust': 1513,\n",
              " 'cost': 1427,\n",
              " 'purchase': 4200,\n",
              " 'foot': 2295,\n",
              " 'square': 4985,\n",
              " 'party': 3825,\n",
              " 'tent': 5283,\n",
              " 'sides': 4764,\n",
              " 'actress': 309,\n",
              " 'received': 4314,\n",
              " 'equity': 2018,\n",
              " 'securities': 4642,\n",
              " 'gymnophobia': 2544,\n",
              " 'years': 5864,\n",
              " 'fossils': 2326,\n",
              " 'rascals': 4283,\n",
              " 'dog': 1773,\n",
              " 'landing': 3024,\n",
              " 'banks': 631,\n",
              " 'musical': 3500,\n",
              " 'hostages': 2709,\n",
              " 'raise': 4269,\n",
              " 'iq': 2897,\n",
              " 'inri': 2848,\n",
              " 'cross': 1505,\n",
              " 'produces': 4127,\n",
              " 'earns': 1874,\n",
              " 'hard': 2579,\n",
              " 'way': 5722,\n",
              " 'founded': 2330,\n",
              " 'athlete': 557,\n",
              " 'makes': 3235,\n",
              " 'sports': 4970,\n",
              " 'merchandise': 3354,\n",
              " 'sales': 4552,\n",
              " 'bends': 712,\n",
              " 'standard': 5001,\n",
              " 'clip': 1197,\n",
              " 'discovered': 1733,\n",
              " 'electricity': 1929,\n",
              " 'contains': 1373,\n",
              " 'norp': 3608,\n",
              " 'space': 4917,\n",
              " 'south': 4909,\n",
              " 'american': 425,\n",
              " 'countries': 1442,\n",
              " 'border': 817,\n",
              " 'album': 388,\n",
              " 'put': 4213,\n",
              " 'beatles': 672,\n",
              " 'cover': 1453,\n",
              " '1967': 135,\n",
              " 'poem': 3977,\n",
              " 'line': 3129,\n",
              " 'grow': 2525,\n",
              " 'old': 3674,\n",
              " 'me': 3315,\n",
              " 'best': 719,\n",
              " 'yet': 5868,\n",
              " 'dental': 1626,\n",
              " 'root': 4506,\n",
              " 'canal': 987,\n",
              " 'war': 5696,\n",
              " 'occur': 3647,\n",
              " 'busiest': 929,\n",
              " 'air': 375,\n",
              " 'season': 4629,\n",
              " 'colored': 1251,\n",
              " 'eye': 2112,\n",
              " 'hook': 2693,\n",
              " 'worms': 5836,\n",
              " 'played': 3962,\n",
              " 'japanese': 2926,\n",
              " 'car': 1012,\n",
              " 'maker': 3234,\n",
              " 'had': 2550,\n",
              " 'biggest': 737,\n",
              " 'percentage': 3868,\n",
              " 'sale': 4551,\n",
              " 'domestic': 1783,\n",
              " 'market': 3270,\n",
              " 'mayor': 3313,\n",
              " 'blasted': 770,\n",
              " '14': 18,\n",
              " 'mile': 3381,\n",
              " 'wide': 5779,\n",
              " 'valley': 5594,\n",
              " 'just': 2970,\n",
              " 'north': 3609,\n",
              " 'prime': 4101,\n",
              " 'minister': 3406,\n",
              " 'months': 3443,\n",
              " 'moon': 3445,\n",
              " 'revolve': 4451,\n",
              " 'around': 522,\n",
              " '49': 214,\n",
              " 'steps': 5038,\n",
              " 'elected': 1923,\n",
              " 'president': 4085,\n",
              " 'sings': 4790,\n",
              " 'themes': 5317,\n",
              " 'directed': 1717,\n",
              " 'jaws': 2928,\n",
              " 'could': 1434,\n",
              " 'indian': 2809,\n",
              " 'tribe': 5484,\n",
              " 'perpetually': 3880,\n",
              " 'doing': 1777,\n",
              " 'battle': 659,\n",
              " 'some': 4888,\n",
              " 'labels': 3011,\n",
              " 'say': 4578,\n",
              " 'nonchlorine': 3598,\n",
              " 'bleach': 771,\n",
              " 'colonies': 1247,\n",
              " 'involved': 2894,\n",
              " 'lives': 3155,\n",
              " 'pictorial': 3915,\n",
              " 'directions': 1719,\n",
              " 'build': 900,\n",
              " 'very': 5624,\n",
              " 'simple': 4780,\n",
              " 'treehouse': 5479,\n",
              " 'board': 790,\n",
              " 'shows': 4757,\n",
              " 'territories': 5292,\n",
              " 'managing': 3246,\n",
              " 'director': 1721,\n",
              " 'occupation': 3645,\n",
              " 'horseshoes': 2705,\n",
              " 'bring': 876,\n",
              " 'luck': 3195,\n",
              " '401': 205,\n",
              " 'plan': 3951,\n",
              " 'pneumonia': 3975,\n",
              " 'three': 5343,\n",
              " 'winter': 5801,\n",
              " 'southern': 4912,\n",
              " 'hemisphere': 2635,\n",
              " 'gringo': 2518,\n",
              " 'northernmost': 3611,\n",
              " 'therapy': 5323,\n",
              " 'attempts': 566,\n",
              " 'elicit': 1939,\n",
              " 'primal': 4098,\n",
              " 'scream': 4610,\n",
              " 'police': 3992,\n",
              " 'department': 1629,\n",
              " 'seized': 4651,\n",
              " 'cocaine': 1221,\n",
              " 'shipment': 4728,\n",
              " 'dangles': 1556,\n",
              " 'tongue': 5389,\n",
              " 'palate': 3794,\n",
              " 'created': 1477,\n",
              " 'dummy': 1854,\n",
              " 'honorary': 2691,\n",
              " 'degree': 1615,\n",
              " 'published': 4189,\n",
              " 'areas': 513,\n",
              " 'forest': 2310,\n",
              " 'start': 5010,\n",
              " 'web': 5735,\n",
              " 'based': 645,\n",
              " 'business': 930,\n",
              " 'brothers': 885,\n",
              " 'syndrome': 5201,\n",
              " 'styloid': 5106,\n",
              " 'process': 4120,\n",
              " 'die': 1692,\n",
              " 'royal': 4518,\n",
              " 'wedding': 5739,\n",
              " 'actor': 307,\n",
              " 'said': 4545,\n",
              " 'day': 1572,\n",
              " 'races': 4251,\n",
              " 'either': 1917,\n",
              " 'dead': 1577,\n",
              " 'watch': 5710,\n",
              " 'stopped': 5061,\n",
              " 'explorer': 2092,\n",
              " 'nicknamed': 3580,\n",
              " 'pilot': 3928,\n",
              " 'began': 693,\n",
              " 'ball': 619,\n",
              " 'hits': 2671,\n",
              " 'foul': 2328,\n",
              " 'pole': 3991,\n",
              " 'hamburgers': 2560,\n",
              " 'taste': 5239,\n",
              " 'like': 3119,\n",
              " 'steakburgers': 5028,\n",
              " 'browser': 889,\n",
              " 'rites': 4478,\n",
              " 'accompanying': 282,\n",
              " 'circumcision': 1167,\n",
              " 'newly': 3570,\n",
              " 'child': 1136,\n",
              " 'education': 1902,\n",
              " '1960': 127,\n",
              " 'commercial': 1277,\n",
              " 'field': 2203,\n",
              " 'cities': 1170,\n",
              " 'cable': 951,\n",
              " 'modem': 3424,\n",
              " 'access': 276,\n",
              " 'sharks': 4714,\n",
              " 'snoogans': 4858,\n",
              " 'shrubs': 4759,\n",
              " 'planted': 3957,\n",
              " 'will': 5787,\n",
              " 'safe': 4541,\n",
              " 'deer': 1605,\n",
              " 'organization': 3717,\n",
              " 'offices': 3665,\n",
              " 'broken': 881,\n",
              " '1972': 141,\n",
              " 'design': 1645,\n",
              " 'ship': 4727,\n",
              " 'titanic': 5371,\n",
              " 'technique': 5258,\n",
              " 'widely': 5780,\n",
              " 'detect': 1658,\n",
              " 'birth': 754,\n",
              " 'defects': 1608,\n",
              " 'daily': 1546,\n",
              " 'requirement': 4411,\n",
              " 'expectant': 2082,\n",
              " 'mother': 3458,\n",
              " 'minute': 3409,\n",
              " 'cigarette': 1163,\n",
              " 'forms': 2320,\n",
              " 'gold': 2469,\n",
              " 'acreage': 296,\n",
              " 'correctly': 1423,\n",
              " 'qigong': 4219,\n",
              " 'beethoven': 690,\n",
              " 'railroad': 4262,\n",
              " 'coal': 1217,\n",
              " 'european': 2044,\n",
              " 'entered': 1996,\n",
              " 'against': 357,\n",
              " 'filmmakers': 2214,\n",
              " 'collabrative': 1235,\n",
              " 'russian': 4536,\n",
              " 'composer': 1309,\n",
              " 'prelude': 4074,\n",
              " 'brought': 886,\n",
              " 'him': 2664,\n",
              " 'fame': 2139,\n",
              " 'fortune': 2323,\n",
              " 'caused': 1055,\n",
              " 'death': 1586,\n",
              " 'king': 2995,\n",
              " 'duke': 1851,\n",
              " 'revolutions': 4450,\n",
              " 'minutes': 3410,\n",
              " 'tallest': 5229,\n",
              " 'mountain': 3465,\n",
              " 'review': 4442,\n",
              " 'journal': 2956,\n",
              " 'slowest': 4837,\n",
              " 'swimming': 5190,\n",
              " 'stroke': 5091,\n",
              " 'astronaut': 552,\n",
              " 'spacewalk': 4921,\n",
              " 'disease': 1734,\n",
              " 'transmitted': 5459,\n",
              " 'anopheles': 456,\n",
              " 'mosquito': 3454,\n",
              " 'rum': 4529,\n",
              " 'so': 4866,\n",
              " 'mixable': 3419,\n",
              " 'brand': 854,\n",
              " 'bar': 633,\n",
              " 'letter': 3097,\n",
              " 'contents': 1376,\n",
              " 'proposition': 4161,\n",
              " '98': 251,\n",
              " 'ground': 2522,\n",
              " 'bombing': 806,\n",
              " '103': 5,\n",
              " '21': 179,\n",
              " 'wrote': 5854,\n",
              " 'paracetamol': 3810,\n",
              " 'powers': 4054,\n",
              " 'weaknesses': 5727,\n",
              " 'ring': 4469,\n",
              " 'bite': 762,\n",
              " 'draws': 1819,\n",
              " 'steel': 5033,\n",
              " 'mill': 3387,\n",
              " 'built': 906,\n",
              " 'diminutive': 1705,\n",
              " 'gymnast': 2542,\n",
              " 'show': 4752,\n",
              " '1984': 155,\n",
              " 'olympics': 3680,\n",
              " 'schools': 4597,\n",
              " 'playing': 3965,\n",
              " 'cry': 1514,\n",
              " 'ad': 312,\n",
              " 'arma': 516,\n",
              " 'mascot': 3288,\n",
              " 'hotel': 2712,\n",
              " 'burned': 923,\n",
              " '1980': 150,\n",
              " 'loss': 3181,\n",
              " '84': 241,\n",
              " 'last': 3039,\n",
              " 'significant': 4770,\n",
              " 'eruption': 2027,\n",
              " 'fathom': 2166,\n",
              " 'penny': 3862,\n",
              " 'black': 764,\n",
              " 'introduced': 2882,\n",
              " 'tragic': 5445,\n",
              " 'hero': 2646,\n",
              " 'owe': 3758,\n",
              " 'success': 5121,\n",
              " '1994': 165,\n",
              " 'other': 3736,\n",
              " 'ways': 5723,\n",
              " 'getting': 2433,\n",
              " 'stretch': 5081,\n",
              " 'marks': 3273,\n",
              " 'besides': 718,\n",
              " 'pregnancy': 4071,\n",
              " 'weight': 5745,\n",
              " 'lifting': 3115,\n",
              " 'brontosauruses': 882,\n",
              " 'eat': 1886,\n",
              " 'bottles': 828,\n",
              " 'good': 2478,\n",
              " 'lead': 3059,\n",
              " '16th': 34,\n",
              " 'sons': 4899,\n",
              " 'molybdenum': 3430,\n",
              " 'lowest': 3193,\n",
              " 'level': 3100,\n",
              " 'judiciary': 2963,\n",
              " 'fought': 2327,\n",
              " 'kill': 2987,\n",
              " 'official': 3666,\n",
              " 'animal': 447,\n",
              " 'direct': 1716,\n",
              " 'size': 4804,\n",
              " 'akita': 387,\n",
              " 'eyes': 2114,\n",
              " 'author': 586,\n",
              " 'about': 269,\n",
              " 'computer': 1315,\n",
              " 'hackers': 2549,\n",
              " 'tracking': 5432,\n",
              " 'founding': 2333,\n",
              " 'member': 3340,\n",
              " 'band': 625,\n",
              " 'beer': 687,\n",
              " 'producing': 4128,\n",
              " 'balance': 617,\n",
              " 'social': 4869,\n",
              " 'security': 4643,\n",
              " 'account': 284,\n",
              " 'italians': 2917,\n",
              " 'call': 967,\n",
              " 'top': 5399,\n",
              " 'psi': 4180,\n",
              " 'sea': 4621,\n",
              " 'romans': 4500,\n",
              " 'mare': 3266,\n",
              " 'nostrum': 3613,\n",
              " 'bet': 722,\n",
              " 'before': 692,\n",
              " 'dealt': 1585,\n",
              " 'came': 976,\n",
              " 'according': 283,\n",
              " '22': 182,\n",
              " 'chicken': 1129,\n",
              " 'egg': 1910,\n",
              " 'flintstones': 2262,\n",
              " 'incompetent': 2802,\n",
              " 'chemicals': 1120,\n",
              " 'lethal': 3096,\n",
              " 'injection': 2838,\n",
              " 'toy': 5428,\n",
              " 'no': 3589,\n",
              " 'apparel': 479,\n",
              " 'wood': 5821,\n",
              " 'pusher': 4209,\n",
              " 'play': 3961,\n",
              " 'poorly': 4012,\n",
              " 'doonesbury': 1795,\n",
              " 'likely': 3121,\n",
              " 'turn': 5516,\n",
              " 'werewolf': 5750,\n",
              " 'constitution': 1365,\n",
              " 'won': 5818,\n",
              " 'fastest': 2160,\n",
              " 'automobile': 592,\n",
              " 'bought': 830,\n",
              " 'stadium': 4989,\n",
              " 'games': 2395,\n",
              " 'speaking': 4929,\n",
              " 'role': 4495,\n",
              " 'poop': 4010,\n",
              " 'different': 1697,\n",
              " 'colors': 1253,\n",
              " 'attacked': 563,\n",
              " '1942': 110,\n",
              " 'girl': 2439,\n",
              " 'affectionate': 348,\n",
              " 'buried': 921,\n",
              " 'remove': 4387,\n",
              " 'wallpaper': 5691,\n",
              " 'tabulates': 5213,\n",
              " 'ballots': 623,\n",
              " 'voting': 5679,\n",
              " 'tradition': 5440,\n",
              " 'ago': 366,\n",
              " 'sink': 4792,\n",
              " 'deepest': 1604,\n",
              " 'area': 512,\n",
              " 'silk': 4774,\n",
              " 'screening': 4612,\n",
              " 'done': 1792,\n",
              " 'latitude': 3045,\n",
              " 'longitude': 3174,\n",
              " 'made': 3211,\n",
              " 'boat': 794,\n",
              " 'gopher': 2482,\n",
              " 'ordinal': 3712,\n",
              " 'screensaver': 4615,\n",
              " 'resident': 4417,\n",
              " 'wreaks': 5843,\n",
              " 'havoc': 2597,\n",
              " 'match': 3296,\n",
              " 'number': 3625,\n",
              " 'rainbow': 4266,\n",
              " 'normal': 3605,\n",
              " 'resting': 4428,\n",
              " 'heart': 2615,\n",
              " 'rate': 4285,\n",
              " 'healthy': 2611,\n",
              " 'adult': 330,\n",
              " 'population': 4019,\n",
              " 'calories': 973,\n",
              " 'stands': 5003,\n",
              " 'creature': 1483,\n",
              " 'scares': 4588,\n",
              " 'deveopment': 1672,\n",
              " 'followed': 2288,\n",
              " 'woman': 5816,\n",
              " 'golfer': 2475,\n",
              " 'earn': 1872,\n",
              " 'million': 3393,\n",
              " 'piece': 3920,\n",
              " 'chessboard': 1125,\n",
              " 'address': 316,\n",
              " 'buy': 942,\n",
              " 'movies': 3476,\n",
              " 'videotape': 5638,\n",
              " 'online': 3687,\n",
              " 'advertizing': 340,\n",
              " 'leading': 3062,\n",
              " 'competitor': 1301,\n",
              " 'dare': 1558,\n",
              " 'knock': 3005,\n",
              " 'shoulder': 4749,\n",
              " 'radio': 4256,\n",
              " 'dollar': 1779,\n",
              " 'equivalent': 2020,\n",
              " 'pounds': 4047,\n",
              " 'approaches': 493,\n",
              " 'systems': 5207,\n",
              " 'analysis': 435,\n",
              " 'doctors': 1769,\n",
              " 'diagnose': 1680,\n",
              " 'bone': 809,\n",
              " 'cancer': 989,\n",
              " 'behind': 699,\n",
              " 'pig': 3922,\n",
              " 'pulls': 4193,\n",
              " 'strings': 5085,\n",
              " 'speaks': 4930,\n",
              " 'speed': 4941,\n",
              " 'developmental': 1670,\n",
              " 'stages': 4992,\n",
              " 'swimmer': 5189,\n",
              " 'portrayed': 4026,\n",
              " 'ocean': 3651,\n",
              " 'poet': 3979,\n",
              " 'win': 5789,\n",
              " 'literature': 3149,\n",
              " '1948': 114,\n",
              " 'join': 2949,\n",
              " 'sonnets': 4898,\n",
              " 'redness': 4339,\n",
              " 'cheeks': 1112,\n",
              " 'blush': 789,\n",
              " '1991': 162,\n",
              " 'challengers': 1090,\n",
              " 'define': 1611,\n",
              " 'fight': 2205,\n",
              " 'recapture': 4312,\n",
              " 'muslims': 3503,\n",
              " 'gaming': 2397,\n",
              " 'devices': 1674,\n",
              " 'dubbed': 1846,\n",
              " 'memphis': 3344,\n",
              " 'dominoes': 1786,\n",
              " 'coach': 1215,\n",
              " 'successful': 5122,\n",
              " 'arometherapy': 521,\n",
              " 'jewish': 2942,\n",
              " 'holiday': 2683,\n",
              " 'saw': 4576,\n",
              " '1973': 142,\n",
              " 'copier': 1407,\n",
              " '1969': 137,\n",
              " 'we': 5724,\n",
              " 'll': 3158,\n",
              " 'guarantee': 2530,\n",
              " 'horse': 2702,\n",
              " 'declared': 1598,\n",
              " 'am': 415,\n",
              " 'down': 1807,\n",
              " 'whores': 5774,\n",
              " 'shan': 4710,\n",
              " 'stop': 5060,\n",
              " 'ripping': 4473,\n",
              " 'them': 5315,\n",
              " 'chocolate': 1148,\n",
              " 'tv': 5522,\n",
              " 'once': 3682,\n",
              " 'contestant': 1379,\n",
              " 'admit': 322,\n",
              " 'picking': 3913,\n",
              " 'toes': 5380,\n",
              " 'shower': 4754,\n",
              " 'soviet': 4915,\n",
              " 'leader': 3060,\n",
              " 'owned': 3761,\n",
              " 'case': 1037,\n",
              " 'individuals': 2814,\n",
              " 'tend': 5278,\n",
              " 'troops': 5496,\n",
              " 'stardust': 5006,\n",
              " 'records': 4329,\n",
              " 'went': 5748,\n",
              " 'serve': 4677,\n",
              " 'but': 934,\n",
              " 'necessarily': 3542,\n",
              " 'consecutively': 1350,\n",
              " 'mountains': 3467,\n",
              " 'lie': 3110,\n",
              " 'between': 726,\n",
              " '1989': 158,\n",
              " 'function': 2373,\n",
              " 'closest': 1205,\n",
              " 'equal': 2011,\n",
              " 'angles': 444,\n",
              " 'cockroaches': 1223,\n",
              " 'opera': 3694,\n",
              " 'interrupted': 2874,\n",
              " 'bulletin': 909,\n",
              " 'assassination': 544,\n",
              " '24': 186,\n",
              " 'hour': 2713,\n",
              " 'clock': 1200,\n",
              " 'instead': 2858,\n",
              " '12': 10,\n",
              " 'lawyer': 3054,\n",
              " 'represented': 4404,\n",
              " 'dreamed': 1821,\n",
              " 'assassinated': 543,\n",
              " '1965': 133,\n",
              " 'basque': 652,\n",
              " 'located': 3162,\n",
              " 'promote': 4146,\n",
              " 'time': 5363,\n",
              " 'dry': 1843,\n",
              " 'ice': 2758,\n",
              " 'powerful': 4053,\n",
              " 'card': 1015,\n",
              " 'intractable': 2879,\n",
              " 'ulysses': 5543,\n",
              " 'crop': 1503,\n",
              " 'failure': 2130,\n",
              " 'korean': 3009,\n",
              " 'served': 4678,\n",
              " 'types': 5532,\n",
              " 'dogs': 1774,\n",
              " 'tails': 5218,\n",
              " 'longest': 3173,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train and test an SVM with the same parameters as before..."
      ],
      "metadata": {
        "id": "XyGMh6ysm3qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "c = 1.5\n",
        "decision_function='ovr'\n",
        "max_iter=-1\n",
        "kernel='sigmoid'\n",
        "degree=2\n",
        "gamma =1.0\n",
        "\n",
        "svm_sig = SVC(C=c, max_iter=max_iter, degree=degree, kernel=kernel, gamma=gamma, decision_function_shape=decision_function)\n",
        "\n",
        "svm_sig.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "g80IxckVmeOi",
        "outputId": "2eaac46d-6c03-41cc-f90d-98948570a529"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.5, degree=2, gamma=1.0, kernel='sigmoid')"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1.5, degree=2, gamma=1.0, kernel=&#x27;sigmoid&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1.5, degree=2, gamma=1.0, kernel=&#x27;sigmoid&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide the Classification Report..."
      ],
      "metadata": {
        "id": "ZaMbDAdgnFlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svm_sig.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_0HDYeOnAMO",
        "outputId": "5ca25f51-89b6-4591-b793-193f6984362b"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ABBR       0.88      0.78      0.82         9\n",
            "        DESC       0.82      0.96      0.89       138\n",
            "        ENTY       0.82      0.74      0.78        94\n",
            "         HUM       0.93      0.88      0.90        65\n",
            "         LOC       0.85      0.88      0.86        81\n",
            "         NUM       0.97      0.86      0.91       113\n",
            "\n",
            "    accuracy                           0.87       500\n",
            "   macro avg       0.88      0.85      0.86       500\n",
            "weighted avg       0.87      0.87      0.87       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train and test a Multinomial Naive Bayes with the same parametres as before..."
      ],
      "metadata": {
        "id": "rPELUepcotAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "MultinomialNB_model = MultinomialNB(alpha=0.1)\n",
        "MultinomialNB_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "QMeC6pgwoiJ6",
        "outputId": "926c2aea-c23c-485d-9e51-0db420e7fad3"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.1)"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide the Classification Report..."
      ],
      "metadata": {
        "id": "CWPkaSJjo2dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = MultinomialNB_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u1G-Ic0oiHO",
        "outputId": "690f8643-667a-47c7-bb18-414cf81b576e"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        ABBR       1.00      0.78      0.88         9\n",
            "        DESC       0.85      0.83      0.84       138\n",
            "        ENTY       0.78      0.61      0.68        94\n",
            "         HUM       0.74      0.94      0.83        65\n",
            "         LOC       0.77      0.90      0.83        81\n",
            "         NUM       0.86      0.81      0.84       113\n",
            "\n",
            "    accuracy                           0.81       500\n",
            "   macro avg       0.83      0.81      0.82       500\n",
            "weighted avg       0.81      0.81      0.81       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations:\n",
        "\n",
        "The first idea of annotation was to annotate the occurrence of some specified couple of words inside a question by looking at the dependency relation(by surronding them with \"#\"). The problem was that during the BOW-Vectorization we loose important informations such as the relative position of words inside a sentence. This lead us to consider \"# where is #\" and \"# is where#\" that is an example of recurent pattern in LOC questions, the same.\n",
        "\n",
        "The second idea was to substitute proper nouns with named_entities paying attention to compound words that refer to a single entity.\n",
        "\n",
        "Results:\n",
        "We trained both the representations on two specyfic models whose parametres were chosen by looking at the previous work of optimization (look at the previous notebooks) and we observed that:\n",
        "\n",
        "- In the SVMs results there are no significant changes from one representation to the other one in therms of f1-score\n",
        "\n",
        "- In the MultinomialNBs results we can see that the second representation leads us to slightly better performances."
      ],
      "metadata": {
        "id": "xz_a9fZjpDfI"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}